#!/usr/bin/env python3
"""
‰∏¶ÂàóÂá¶ÁêÜ„ÅÆÊÄßËÉΩ„ÉÜ„Çπ„Éà„Çπ„ÇØ„É™„Éó„Éà

‰ΩøÁî®ÊñπÊ≥ï:
python test_parallel_performance.py

„Åì„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„ÅØ‰ª•‰∏ã„Çí„ÉÜ„Çπ„Éà„Åó„Åæ„Åô:
1. ÂæìÊù•„ÅÆÈ†ÜÊ¨°Âá¶ÁêÜ vs Êñ∞„Åó„ÅÑ‰∏¶ÂàóÂá¶ÁêÜ„ÅÆÈÄüÂ∫¶ÊØîËºÉ
2. Áï∞„Å™„ÇãÂêåÊôÇÂÆüË°åÊï∞„Åß„ÅÆÊÄßËÉΩÊ∏¨ÂÆö
3. ‰∏¶ÂàóÂá¶ÁêÜ„ÅÆÊ≠£Á¢∫ÊÄßÊ§úË®º
"""

import asyncio
import time
import json
import os
import sys
from typing import Dict, List

# „Éë„Çπ„ÅÆËøΩÂä†
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.config import settings
from app.services.description.openai import OpenAIDescriptionService

class PerformanceTestHelper:
    """‰∏¶ÂàóÂá¶ÁêÜ„ÅÆ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ„ÉÜ„Çπ„ÉàÁî®„Éò„É´„Éë„Éº„ÇØ„É©„Çπ"""
    
    def __init__(self):
        self.service = OpenAIDescriptionService()
    
    def create_test_data(self, categories: int = 3, items_per_category: int = 9) -> Dict:
        """„ÉÜ„Çπ„ÉàÁî®„ÅÆ„Çµ„É≥„Éó„É´„É°„Éã„É•„Éº„Éá„Éº„Çø„ÇíÁîüÊàê"""
        test_data = {}
        
        for i in range(categories):
            category_name = f"Test Category {i+1}"
            items = []
            
            for j in range(items_per_category):
                items.append({
                    "japanese_name": f"„ÉÜ„Çπ„ÉàÊñôÁêÜ{i+1}-{j+1}",
                    "english_name": f"Test Dish {i+1}-{j+1}",
                    "price": "¬•1000"
                })
            
            test_data[category_name] = items
        
        return test_data
    
    async def test_sequential_processing(self, test_data: Dict) -> Dict:
        """ÂæìÊù•„ÅÆÈ†ÜÊ¨°Âá¶ÁêÜ„Çí„ÉÜ„Çπ„ÉàÔºàmockÔºâ"""
        print("üîÑ Testing sequential processing...")
        start_time = time.time()
        
        # Ê®°Êì¨ÁöÑ„Å™È†ÜÊ¨°Âá¶ÁêÜÔºàÂêÑ„ÉÅ„É£„É≥„ÇØ„ÇíÈ†ÜÊ¨°Âá¶ÁêÜÔºâ
        total_chunks = 0
        for category, items in test_data.items():
            chunk_size = settings.PROCESSING_CHUNK_SIZE
            chunks_in_category = (len(items) + chunk_size - 1) // chunk_size
            total_chunks += chunks_in_category
            
            # ÂêÑ„ÉÅ„É£„É≥„ÇØ„ÇíÈ†ÜÊ¨°Ê®°Êì¨Âá¶ÁêÜ
            for i in range(chunks_in_category):
                await asyncio.sleep(0.5)  # Ê®°Êì¨AIÂá¶ÁêÜÊôÇÈñì
                print(f"  Sequential: {category} chunk {i+1}/{chunks_in_category}")
        
        end_time = time.time()
        
        return {
            "method": "sequential",
            "total_time": end_time - start_time,
            "total_chunks": total_chunks,
            "chunks_per_second": total_chunks / (end_time - start_time)
        }
    
    async def test_parallel_processing(self, test_data: Dict, concurrent_limit: int = 5) -> Dict:
        """Êñ∞„Åó„ÅÑ‰∏¶ÂàóÂá¶ÁêÜ„Çí„ÉÜ„Çπ„Éà"""
        print(f"üöÄ Testing parallel processing (concurrent_limit={concurrent_limit})...")
        start_time = time.time()
        
        # ÂÆüÈöõ„ÅÆ‰∏¶ÂàóÂá¶ÁêÜ„Çµ„Éº„Éì„Çπ„Çí‰ΩøÁî®Ôºà„Åü„Å†„ÅóAPIÂëº„Å≥Âá∫„Åó„ÅØÊ®°Êì¨Ôºâ
        original_settings = settings.CONCURRENT_CHUNK_LIMIT
        settings.CONCURRENT_CHUNK_LIMIT = concurrent_limit
        
        try:
            # APIÂëº„Å≥Âá∫„Åó„ÇíÊ®°Êì¨„Åô„Çã„Åü„ÇÅ„ÄÅ‰∏ÄÊôÇÁöÑ„Å´„É°„ÇΩ„ÉÉ„Éâ„ÇíÁΩÆ„ÅçÊèõ„Åà
            original_process_chunk = self.service.process_chunk
            
            async def mock_process_chunk(category, chunk, chunk_number, total_chunks, session_id=None):
                await asyncio.sleep(0.5)  # Ê®°Êì¨AIÂá¶ÁêÜÊôÇÈñì
                print(f"  Parallel: {category} chunk {chunk_number}/{total_chunks}")
                return [{"test": "result"} for _ in chunk]
            
            self.service.process_chunk = mock_process_chunk
            
            # ‰∏¶ÂàóÂá¶ÁêÜ„ÇíÂÆüË°å
            result = await self.service.process_category_parallel("Test Category", list(test_data.values())[0])
            
            end_time = time.time()
            
            total_chunks = sum((len(items) + settings.PROCESSING_CHUNK_SIZE - 1) // settings.PROCESSING_CHUNK_SIZE 
                             for items in test_data.values())
            
            return {
                "method": "parallel",
                "concurrent_limit": concurrent_limit,
                "total_time": end_time - start_time,
                "total_chunks": total_chunks,
                "chunks_per_second": total_chunks / (end_time - start_time),
                "result_items": len(result)
            }
            
        finally:
            # ÂÖÉ„ÅÆË®≠ÂÆö„Å®„É°„ÇΩ„ÉÉ„Éâ„ÇíÂæ©ÂÖÉ
            settings.CONCURRENT_CHUNK_LIMIT = original_settings
            self.service.process_chunk = original_process_chunk
    
    async def run_performance_comparison(self):
        """Á∑èÂêàÁöÑ„Å™ÊÄßËÉΩÊØîËºÉ„ÉÜ„Çπ„Éà„ÇíÂÆüË°å"""
        print("üß™ Starting parallel processing performance test...")
        print("=" * 60)
        
        # „ÉÜ„Çπ„Éà„Éá„Éº„Çø„ÇíÁîüÊàê
        test_data = self.create_test_data(categories=3, items_per_category=9)
        total_items = sum(len(items) for items in test_data.values())
        
        print(f"üìä Test Data: {len(test_data)} categories, {total_items} total items")
        print(f"üì¶ Chunk size: {settings.PROCESSING_CHUNK_SIZE}")
        print()
        
        # È†ÜÊ¨°Âá¶ÁêÜ„ÉÜ„Çπ„Éà
        sequential_result = await self.test_sequential_processing(test_data)
        print(f"‚è±Ô∏è Sequential: {sequential_result['total_time']:.2f}s, {sequential_result['chunks_per_second']:.2f} chunks/sec")
        print()
        
        # Êßò„ÄÖ„Å™‰∏¶ÂàóÊï∞„Åß„ÅÆ‰∏¶ÂàóÂá¶ÁêÜ„ÉÜ„Çπ„Éà
        parallel_results = []
        concurrent_limits = [2, 3, 5, 8]
        
        for limit in concurrent_limits:
            parallel_result = await self.test_parallel_processing(test_data, limit)
            parallel_results.append(parallel_result)
            
            speedup = sequential_result['total_time'] / parallel_result['total_time']
            efficiency = speedup / limit * 100
            
            print(f"üöÄ Parallel (limit={limit}): {parallel_result['total_time']:.2f}s, "
                  f"{parallel_result['chunks_per_second']:.2f} chunks/sec")
            print(f"   üìà Speedup: {speedup:.2f}x, Efficiency: {efficiency:.1f}%")
            print()
        
        # ÁµêÊûú„ÅÆÂàÜÊûê
        best_parallel = min(parallel_results, key=lambda x: x['total_time'])
        best_speedup = sequential_result['total_time'] / best_parallel['total_time']
        
        print("=" * 60)
        print("üìä PERFORMANCE SUMMARY")
        print("=" * 60)
        print(f"üêå Sequential Processing: {sequential_result['total_time']:.2f}s")
        print(f"üöÄ Best Parallel (limit={best_parallel['concurrent_limit']}): {best_parallel['total_time']:.2f}s")
        print(f"üìà Maximum Speedup: {best_speedup:.2f}x ({best_speedup*100-100:.1f}% faster)")
        print(f"üí° Recommended concurrent limit: {best_parallel['concurrent_limit']}")
        
        # Ë®≠ÂÆöÊé®Â•®ÂÄ§
        print()
        print("‚öôÔ∏è RECOMMENDED SETTINGS")
        print("=" * 30)
        print(f"CONCURRENT_CHUNK_LIMIT={best_parallel['concurrent_limit']}")
        if len(test_data) > 1:
            print("ENABLE_CATEGORY_PARALLEL=true  # For multiple categories")
        else:
            print("ENABLE_CATEGORY_PARALLEL=false  # Single category test")

async def main():
    """„É°„Ç§„É≥ÂÆüË°åÈñ¢Êï∞"""
    if not settings.OPENAI_API_KEY:
        print("‚ö†Ô∏è OPENAI_API_KEY not set. This test uses mock API calls.")
        print("   Set OPENAI_API_KEY to test with real API calls.")
        print()
    
    tester = PerformanceTestHelper()
    await tester.run_performance_comparison()

if __name__ == "__main__":
    print("üöÄ Menu Processor - Parallel Processing Performance Test")
    print("=" * 60)
    asyncio.run(main()) 