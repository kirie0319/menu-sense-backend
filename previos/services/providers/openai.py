"""
ğŸ¤– OpenAI Provider Service

OpenAI GPTã‚’ä½¿ç”¨ã—ãŸçµ±åˆã‚µãƒ¼ãƒ“ã‚¹
- Categoryåˆ†é¡: ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
- Descriptionç”Ÿæˆ: è©³ç´°èª¬æ˜ã®ç”Ÿæˆ

æ—¢å­˜ã®app.services.category.openai + app.services.description.openaiã‚’çµ±åˆ
"""

import json
import asyncio
from typing import Optional, Dict, List, Any
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum

try:
    import openai
    from openai import AsyncOpenAI
except ImportError:
    openai = None
    AsyncOpenAI = None

from app.core.config.ai import ai_settings
from app.core.config.processing import processing_settings

# CategoryResult class definition (moved from external import)
class CategoryProvider(Enum):
    """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆ—æŒ™å‹"""
    OPENAI = "openai"
    GOOGLE_TRANSLATE = "google_translate"
    ENHANCED = "enhanced"

class CategoryResult(BaseModel):
    """
    ã‚«ãƒ†ã‚´ãƒªåˆ†é¡çµæœã‚’æ ¼ç´ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    # æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
    success: bool
    categories: Dict[str, List[Dict]] = {}
    uncategorized: List[str] = []
    error: Optional[str] = None
    metadata: Dict = {}
    
    # Enhancedæ©Ÿèƒ½è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    total_items: Optional[int] = Field(default=None, description="ç·ã‚¢ã‚¤ãƒ†ãƒ æ•°")
    categorized_items: Optional[int] = Field(default=None, description="åˆ†é¡æ¸ˆã¿ã‚¢ã‚¤ãƒ†ãƒ æ•°")
    processing_time: Optional[float] = Field(default=None, description="å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰")
    categorization_method: Optional[str] = Field(default=None, description="åˆ†é¡æ‰‹æ³•")
    
    # å“è³ªæŒ‡æ¨™ï¼ˆEnhancedæ©Ÿèƒ½ï¼‰
    quality_score: Optional[float] = Field(default=None, description="å“è³ªã‚¹ã‚³ã‚¢ (0-1)")
    confidence: Optional[float] = Field(default=None, description="ä¿¡é ¼åº¦ (0-1)")
    coverage_score: Optional[float] = Field(default=None, description="åˆ†é¡ã‚«ãƒãƒ¬ãƒƒã‚¸")
    balance_score: Optional[float] = Field(default=None, description="ã‚«ãƒ†ã‚´ãƒªãƒãƒ©ãƒ³ã‚¹")
    accuracy_estimate: Optional[float] = Field(default=None, description="ç²¾åº¦æ¨å®š")
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆæ—¢å­˜äº’æ›æ€§ç¶­æŒï¼‰"""
        result = {
            "success": self.success,
            "categories": self.categories,
            "uncategorized": self.uncategorized
        }
        if self.error:
            result["error"] = self.error
        if self.metadata:
            result.update(self.metadata)
        return result

# DescriptionResult class definition (moved from external import)
class DescriptionProvider(str, Enum):
    """è©³ç´°èª¬æ˜ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å®šç¾©"""
    OPENAI = "openai"
    ENHANCED = "enhanced"

class DescriptionResult(BaseModel):
    """
    è©³ç´°èª¬æ˜ç”Ÿæˆçµæœã‚’æ ¼ç´ã™ã‚‹ã‚¯ãƒ©ã‚¹
    """
    
    # æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰
    success: bool
    final_menu: Dict[str, List[Dict]] = {}
    description_method: str = ""
    error: Optional[str] = None
    metadata: Dict = {}
    
    # Enhancedæ©Ÿèƒ½è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    total_items: Optional[int] = Field(default=None, description="ç·ã‚¢ã‚¤ãƒ†ãƒ æ•°")
    described_items: Optional[int] = Field(default=None, description="èª¬æ˜è¿½åŠ æ¸ˆã¿ã‚¢ã‚¤ãƒ†ãƒ æ•°")
    processing_time: Optional[float] = Field(default=None, description="å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰")
    
    # å“è³ªæŒ‡æ¨™ï¼ˆEnhancedæ©Ÿèƒ½ï¼‰
    quality_score: Optional[float] = Field(default=None, description="å“è³ªã‚¹ã‚³ã‚¢ (0-1)")
    confidence: Optional[float] = Field(default=None, description="ä¿¡é ¼åº¦ (0-1)")
    description_coverage: Optional[float] = Field(default=None, description="èª¬æ˜ã‚«ãƒãƒ¬ãƒƒã‚¸")
    description_quality: Optional[float] = Field(default=None, description="èª¬æ˜å“è³ª")
    cultural_accuracy: Optional[float] = Field(default=None, description="æ–‡åŒ–çš„æ­£ç¢ºæ€§")
    
    # çµ±è¨ˆæƒ…å ±ï¼ˆEnhancedæ©Ÿèƒ½ï¼‰
    failed_descriptions: List[str] = Field(default_factory=list, description="èª¬æ˜ç”Ÿæˆå¤±æ•—ã‚¢ã‚¤ãƒ†ãƒ ")
    description_stats: Dict[str, Any] = Field(default_factory=dict, description="èª¬æ˜çµ±è¨ˆ")
    fallback_used: bool = Field(default=False, description="ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ãƒ•ãƒ©ã‚°")
    
    def to_dict(self) -> Dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆæ—¢å­˜äº’æ›æ€§ç¶­æŒï¼‰"""
        result = {
            "success": self.success,
            "final_menu": self.final_menu,
            "description_method": self.description_method
        }
        if self.error:
            result["error"] = self.error
        if self.metadata:
            result.update(self.metadata)
        return result


class OpenAIProviderService:
    """OpenAIçµ±åˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.service_name = "OpenAIProviderService"
        self.client = None
        self._initialize_client()
        # ä¸¦åˆ—å‡¦ç†ç”¨ã‚»ãƒãƒ•ã‚©
        self.semaphore = asyncio.Semaphore(processing_settings.concurrent_chunk_limit)
    
    def _initialize_client(self):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            if not openai or not AsyncOpenAI:
                print("âŒ openai package not installed. Install with: pip install openai")
                return
                
            if ai_settings.openai_api_key:
                self.client = AsyncOpenAI(
                    api_key=ai_settings.openai_api_key,
                    timeout=ai_settings.openai_timeout,
                    max_retries=ai_settings.openai_max_retries
                )
                print("ğŸ”§ OpenAI Provider Service initialized successfully")
            else:
                print("âš ï¸ OPENAI_API_KEY not set")
                
        except Exception as e:
            print(f"âŒ Failed to initialize OpenAI Provider Service: {e}")
            self.client = None
    
    def is_available(self) -> bool:
        """ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return self.client is not None and bool(ai_settings.openai_api_key)
    
    # ==========================================
    # Category Classification Features
    # ==========================================
    
    def get_categorize_function_schema(self) -> dict:
        """ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ç”¨ã®Function Callingã‚¹ã‚­ãƒ¼ãƒã‚’å–å¾—"""
        return {
            "name": "categorize_menu_items",
            "description": "æ—¥æœ¬èªã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã¦ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ã™ã‚‹",
            "parameters": {
                "type": "object",
                "properties": {
                    "categories": {
                        "type": "object",
                        "properties": {
                            "å‰èœ": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string", "description": "æ–™ç†å"},
                                        "price": {"type": "string", "description": "ä¾¡æ ¼"},
                                        "description": {"type": "string", "description": "ç°¡æ½”ãªèª¬æ˜"}
                                    },
                                    "required": ["name"]
                                }
                            },
                            "ãƒ¡ã‚¤ãƒ³": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string", "description": "æ–™ç†å"},
                                        "price": {"type": "string", "description": "ä¾¡æ ¼"},
                                        "description": {"type": "string", "description": "ç°¡æ½”ãªèª¬æ˜"}
                                    },
                                    "required": ["name"]
                                }
                            },
                            "ãƒ‰ãƒªãƒ³ã‚¯": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string", "description": "æ–™ç†å"},
                                        "price": {"type": "string", "description": "ä¾¡æ ¼"},
                                        "description": {"type": "string", "description": "ç°¡æ½”ãªèª¬æ˜"}
                                    },
                                    "required": ["name"]
                                }
                            },
                            "ãƒ‡ã‚¶ãƒ¼ãƒˆ": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "name": {"type": "string", "description": "æ–™ç†å"},
                                        "price": {"type": "string", "description": "ä¾¡æ ¼"},
                                        "description": {"type": "string", "description": "ç°¡æ½”ãªèª¬æ˜"}
                                    },
                                    "required": ["name"]
                                }
                            }
                        },
                        "required": ["å‰èœ", "ãƒ¡ã‚¤ãƒ³", "ãƒ‰ãƒªãƒ³ã‚¯", "ãƒ‡ã‚¶ãƒ¼ãƒˆ"]
                    },
                    "uncategorized": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "åˆ†é¡ã§ããªã‹ã£ãŸé …ç›®"
                    }
                },
                "required": ["categories", "uncategorized"]
            }
        }
    
    async def categorize_menu(
        self, 
        extracted_text: str, 
        session_id: Optional[str] = None
    ) -> CategoryResult:
        """
        OpenAI Function Callingã‚’ä½¿ã£ã¦ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
        
        Args:
            extracted_text: OCRã§æŠ½å‡ºã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆ
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆé€²è¡ŒçŠ¶æ³é€šçŸ¥ç”¨ï¼‰
            
        Returns:
            CategoryResult: åˆ†é¡çµæœ
        """
        print("ğŸ“‹ Starting Japanese menu categorization with OpenAI Function Calling...")
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        if not self.is_available():
            return CategoryResult(
                success=False,
                error="OpenAI API is not available",
                metadata={
                    "error_type": "service_unavailable",
                    "suggestions": [
                        "Set OPENAI_API_KEY environment variable",
                        "Install openai package: pip install openai",
                        "Check internet connectivity"
                    ]
                }
            )
        
        # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if not extracted_text or len(extracted_text.strip()) < 5:
            return CategoryResult(
                success=False,
                error="Invalid input text",
                metadata={
                    "error_type": "invalid_input",
                    "text_length": len(extracted_text),
                    "suggestions": [
                        "Provide menu text with at least 5 characters",
                        "Ensure text is not empty",
                        "Check OCR extraction results"
                    ]
                }
            )
        
        try:
            # Function Callingç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ
            messages = [
                {
                    "role": "user",
                    "content": f"""ä»¥ä¸‹ã®æ—¥æœ¬èªãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€æ–™ç†ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«æ•´ç†ã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{extracted_text}

è¦ä»¶:
1. æ–™ç†åã‚’æŠ½å‡º
2. é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ï¼ˆå‰èœã€ãƒ¡ã‚¤ãƒ³ã€ãƒ‰ãƒªãƒ³ã‚¯ã€ãƒ‡ã‚¶ãƒ¼ãƒˆãªã©ï¼‰
3. ä¾¡æ ¼ãŒã‚ã‚Œã°æŠ½å‡º
4. æ—¥æœ¬èªã®ã¾ã¾å‡¦ç†ï¼ˆç¿»è¨³ã¯ã—ãªã„ï¼‰
5. æ–™ç†åãŒæ˜ç¢ºã§ãªã„å ´åˆã¯ã€uncategorizedã«å«ã‚ã¦ãã ã•ã„
"""
                }
            ]
            
            # OpenAI Function Callingã‚’å®Ÿè¡Œ
            response = await self.call_openai_with_retry(
                messages=messages,
                functions=[self.get_categorize_function_schema()],
                function_call={"name": "categorize_menu_items"}
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ
            function_call = response.choices[0].message.function_call
            if function_call and function_call.name == "categorize_menu_items":
                result = json.loads(function_call.arguments)
                
                categories = result.get("categories", {})
                uncategorized = result.get("uncategorized", [])
                
                # æˆåŠŸãƒ­ã‚°
                total_items = sum(len(items) for items in categories.values())
                print(f"âœ… OpenAI Categorization Complete: {total_items} items in {len(categories)} categories")
                
                return CategoryResult(
                    success=True,
                    categories=categories,
                    uncategorized=uncategorized,
                    metadata={
                        "total_items": total_items,
                        "total_categories": len(categories),
                        "uncategorized_count": len(uncategorized),
                        "categorization_method": "openai_function_calling",
                        "model": ai_settings.openai_model,
                        "text_length": len(extracted_text)
                    }
                )
            else:
                raise ValueError("Function call not found in response")
                
        except Exception as e:
            print(f"âŒ OpenAI Categorization Failed: {e}")
            
            return CategoryResult(
                success=False,
                error=f"OpenAI categorization error: {str(e)}",
                metadata={
                    "error_type": self._get_error_type(e),
                    "original_error": str(e),
                    "suggestions": self._get_error_suggestions(e),
                    "categorization_method": "openai_function_calling",
                    "model": ai_settings.openai_model,
                    "text_length": len(extracted_text)
                }
            )
    
    # ==========================================
    # Description Generation Features
    # ==========================================
    
    def generate_description(
        self,
        japanese_name: str,
        english_name: str,
        category: str = "Other"
    ) -> Dict:
        """
        å€‹åˆ¥ã‚¢ã‚¤ãƒ†ãƒ ã®è©³ç´°èª¬æ˜ã‚’ç”Ÿæˆ
        
        Args:
            japanese_name: æ—¥æœ¬èªå
            english_name: è‹±èªå
            category: ã‚«ãƒ†ã‚´ãƒª
            
        Returns:
            Dict: èª¬æ˜ç”Ÿæˆçµæœ
        """
        if not self.is_available():
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª¬æ˜
            fallback_description = f"Traditional Japanese {category.lower()} with authentic flavors and high-quality ingredients."
            return {
                'success': True,
                'description': fallback_description,
                'service': 'Fallback Description'
            }
        
        try:
            # å€‹åˆ¥ã‚¢ã‚¤ãƒ†ãƒ ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            prompt = f"""Please generate a detailed English description for this Japanese dish for foreign tourists:

Japanese Name: {japanese_name}
English Name: {english_name}
Category: {category}

Requirements:
1. Create a detailed description in English (30-80 words)
2. Include cooking method, key ingredients, and flavor profile
3. Add cultural context that tourists would find interesting
4. Use tourist-friendly language that's easy to understand
5. Make it appealing and informative

Please respond with only the description text, no additional formatting or explanation."""

            messages = [
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            # OpenAI APIå‘¼ã³å‡ºã—ï¼ˆåŒæœŸç‰ˆï¼‰
            response = self.call_openai_with_retry_sync(messages, max_retries=2)
            description = response.choices[0].message.content.strip()
            
            # èª¬æ˜ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            description = self.clean_description_text(description)
            
            return {
                'success': True,
                'description': description,
                'service': 'OpenAI Description'
            }
            
        except Exception as e:
            print(f"âŒ Individual description generation failed: {str(e)}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            fallback_description = f"Delicious {english_name} - a traditional {category.lower()} dish with authentic Japanese flavors."
            return {
                'success': True,
                'description': fallback_description,
                'service': 'Error Fallback Description'
            }
    
    async def add_descriptions(
        self, 
        translated_data: dict, 
        session_id: Optional[str] = None
    ) -> DescriptionResult:
        """
        ç¿»è¨³ã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«è©³ç´°èª¬æ˜ã‚’è¿½åŠ ï¼ˆä¸¦åˆ—ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ç‰ˆï¼‰
        
        Args:
            translated_data: ç¿»è¨³ã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆé€²è¡ŒçŠ¶æ³é€šçŸ¥ç”¨ï¼‰
            
        Returns:
            DescriptionResult: è©³ç´°èª¬æ˜ç”Ÿæˆçµæœ
        """
        print("ğŸ“ Starting detailed description generation with OpenAI (Parallel Chunked Processing)...")
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        if not self.is_available():
            return DescriptionResult(
                success=False,
                description_method="openai",
                error="OpenAI API is not available",
                metadata={
                    "error_type": "service_unavailable",
                    "suggestions": [
                        "Set OPENAI_API_KEY environment variable",
                        "Install openai package: pip install openai",
                        "Check OpenAI API access permissions",
                        "Verify internet connectivity"
                    ]
                }
            )
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if not self.validate_translated_data(translated_data):
            return DescriptionResult(
                success=False,
                description_method="openai",
                error="Invalid translated data",
                metadata={
                    "error_type": "invalid_input",
                    "suggestions": [
                        "Provide valid translated menu data",
                        "Ensure at least one category has menu items",
                        "Check translated data structure format"
                    ]
                }
            )
        
        try:
            final_menu = {}
            total_items = sum(len(items) for items in translated_data.values())
            
            print(f"ğŸ”¢ Total items to process: {total_items}")
            print(f"ğŸš€ Parallel processing enabled with max {processing_settings.concurrent_chunk_limit} concurrent chunks")
            
            # å„ã‚«ãƒ†ã‚´ãƒªã‚’ä¸¦åˆ—å‡¦ç†
            for category, items in translated_data.items():
                if items:  # ç©ºã§ãªã„ã‚«ãƒ†ã‚´ãƒªã®ã¿å‡¦ç†
                    category_results = await self.process_category_parallel(category, items, session_id)
                    final_menu[category] = category_results
            
            total_processed = sum(len(items) for items in final_menu.values())
            
            print(f"âœ… OpenAI Description Generation Complete: {total_processed} items processed")
            
            return DescriptionResult(
                success=True,
                final_menu=final_menu,
                description_method="openai_parallel_chunked",
                metadata={
                    "total_items": total_processed,
                    "categories_processed": len(final_menu),
                    "processing_mode": "parallel_chunked",
                    "model": ai_settings.openai_model,
                    "concurrent_chunks": processing_settings.concurrent_chunk_limit
                }
            )
            
        except Exception as e:
            print(f"âŒ OpenAI Description Generation Failed: {e}")
            
            return DescriptionResult(
                success=False,
                description_method="openai",
                error=f"OpenAI description generation error: {str(e)}",
                metadata={
                    "error_type": self._get_error_type(e),
                    "original_error": str(e),
                    "suggestions": self._get_error_suggestions(e),
                    "model": ai_settings.openai_model
                }
            )
    
    # ==========================================
    # Utility Methods
    # ==========================================
    
    async def call_openai_with_retry(self, messages, functions=None, function_call=None, max_retries=3):
        """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãã§OpenAI APIã‚’å‘¼ã³å‡ºã™ãƒªãƒˆãƒ©ã‚¤é–¢æ•°ï¼ˆéåŒæœŸç‰ˆï¼‰"""
        if not self.is_available():
            raise Exception("OpenAI API is not available")
        
        for attempt in range(max_retries + 1):
            try:
                kwargs = {
                    "model": ai_settings.openai_model,
                    "messages": messages
                }
                
                if functions:
                    kwargs["functions"] = functions
                if function_call:
                    kwargs["function_call"] = function_call
                
                response = await self.client.chat.completions.create(**kwargs)
                return response
                
            except openai.RateLimitError as e:
                if attempt == max_retries:
                    raise Exception(f"Rate limit exceeded after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = processing_settings.retry_base_delay ** attempt
                print(f"â³ Rate limit hit, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                await asyncio.sleep(wait_time)
                
            except (openai.APITimeoutError, openai.APIConnectionError) as e:
                if attempt == max_retries:
                    raise Exception(f"API error after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = processing_settings.retry_base_delay ** attempt
                print(f"â³ API error, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                await asyncio.sleep(wait_time)
                
            except Exception as e:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«å¤±æ•—
                raise Exception(f"OpenAI API error: {str(e)}")
    
    def call_openai_with_retry_sync(self, messages, max_retries=2):
        """åŒæœŸç‰ˆãƒªãƒˆãƒ©ã‚¤é–¢æ•°ï¼ˆgenerate_descriptionç”¨ï¼‰"""
        if not self.is_available():
            raise Exception("OpenAI API is not available")
        
        import time
        
        # åŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        sync_client = openai.OpenAI(
            api_key=ai_settings.openai_api_key,
            timeout=ai_settings.openai_timeout,
            max_retries=ai_settings.openai_max_retries
        )
        
        for attempt in range(max_retries + 1):
            try:
                response = sync_client.chat.completions.create(
                    model=ai_settings.openai_model,
                    messages=messages
                )
                return response
                
            except openai.RateLimitError as e:
                if attempt == max_retries:
                    raise Exception(f"Rate limit exceeded after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = processing_settings.retry_base_delay ** attempt
                print(f"â³ Rate limit hit, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                time.sleep(wait_time)
                
            except Exception as e:
                raise Exception(f"OpenAI API error: {str(e)}")
    
    def validate_translated_data(self, translated_data: Dict) -> bool:
        """ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not translated_data or not isinstance(translated_data, dict):
            return False
        
        # å°‘ãªãã¨ã‚‚1ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«ã‚¢ã‚¤ãƒ†ãƒ ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        has_items = any(
            isinstance(items, list) and len(items) > 0 
            for items in translated_data.values()
        )
        
        return has_items
    
    def clean_description_text(self, description: str) -> str:
        """èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if not description:
            return ""
        
        # ä¸è¦ãªå¼•ç”¨ç¬¦ã‚’å‰Šé™¤
        description = description.strip().strip('"').strip("'")
        
        # æ”¹è¡Œã‚’é™¤å»
        description = description.replace('\n', ' ').replace('\r', ' ')
        
        # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ã‚’å˜ä¸€ã‚¹ãƒšãƒ¼ã‚¹ã«
        import re
        description = re.sub(r'\s+', ' ', description)
        
        return description.strip()
    
    async def process_category_parallel(
        self,
        category: str,
        items: list,
        session_id: Optional[str] = None
    ) -> list:
        """ã‚«ãƒ†ã‚´ãƒªå†…ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ä¸¦åˆ—ãƒãƒ£ãƒ³ã‚¯å‡¦ç†"""
        if not items:
            return []
        
        print(f"ğŸ”„ Processing category: {category} ({len(items)} items) - PARALLEL MODE")
        
        # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        chunk_size = processing_settings.processing_chunk_size
        chunks = []
        
        for i in range(0, len(items), chunk_size):
            chunk = items[i:i + chunk_size]
            chunk_number = (i // chunk_size) + 1
            total_chunks = (len(items) + chunk_size - 1) // chunk_size
            chunks.append((chunk, chunk_number, total_chunks))
        
        print(f"  ğŸ“¦ Created {len(chunks)} chunks for parallel processing")
        
        # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—ã§å‡¦ç†
        tasks = []
        for chunk, chunk_number, total_chunks in chunks:
            task = self.process_chunk_with_semaphore(
                category, chunk, chunk_number, total_chunks, session_id
            )
            tasks.append(task)
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        print(f"  ğŸš€ Starting {len(tasks)} parallel chunk tasks...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # çµæœã‚’å‡¦ç†
        category_results = []
        successful_chunks = 0
        
        # ãƒãƒ£ãƒ³ã‚¯ç•ªå·ã§ã‚½ãƒ¼ãƒˆï¼ˆå…ƒã®é †åºã‚’ç¶­æŒï¼‰
        sorted_results = []
        for result in results:
            if isinstance(result, tuple):
                sorted_results.append(result)
            else:
                print(f"  âš ï¸ Exception in parallel processing: {result}")
        
        sorted_results.sort(key=lambda x: x[0])  # chunk_numberã§ã‚½ãƒ¼ãƒˆ
        
        for chunk_number, chunk_result, error in sorted_results:
            if error:
                print(f"  âš ï¸ Chunk {chunk_number} failed: {error}")
            elif chunk_result:
                category_results.extend(chunk_result)
                successful_chunks += 1
        
        print(f"  âœ… Parallel processing complete: {successful_chunks} successful chunks")
        
        return category_results
    
    async def process_chunk_with_semaphore(
        self, 
        category: str, 
        chunk: list, 
        chunk_number: int, 
        total_chunks: int,
        session_id: Optional[str] = None
    ) -> tuple:
        """ã‚»ãƒãƒ•ã‚©ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—å‡¦ç†"""
        async with self.semaphore:
            try:
                # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚’å®Ÿè¡Œ
                result = await self.process_chunk(category, chunk, chunk_number, total_chunks, session_id)
                return (chunk_number, result, None)  # (chunk_number, result, error)
                
            except Exception as e:
                print(f"  âŒ Error in parallel chunk {chunk_number}/{total_chunks}: {e}")
                return (chunk_number, None, str(e))
    
    async def process_chunk(
        self, 
        category: str, 
        chunk: list, 
        chunk_number: int, 
        total_chunks: int,
        session_id: Optional[str] = None
    ) -> list:
        """ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¦è©³ç´°èª¬æ˜ã‚’è¿½åŠ """
        print(f"  ğŸ“¦ Processing chunk {chunk_number}/{total_chunks} ({len(chunk)} items)")
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            messages = [
                {
                    "role": "user",
                    "content": self.create_description_prompt(category, chunk)
                }
            ]
            
            # OpenAI APIå‘¼ã³å‡ºã—
            response = await self.call_openai_with_retry(messages, max_retries=2)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡º
            content = response.choices[0].message.content
            chunk_result = self.extract_json_from_response(content)
            
            if 'final_menu' in chunk_result and category in chunk_result['final_menu']:
                new_items = chunk_result['final_menu'][category]
                
                # èª¬æ˜ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for item in new_items:
                    if item.get("description"):
                        item["description"] = self.clean_description_text(item["description"])
                
                print(f"    âœ… Successfully processed {len(new_items)} items in chunk")
                return new_items
            else:
                raise ValueError("Invalid response format")
                
        except Exception as chunk_error:
            print(f"âš ï¸ Chunk processing error: {chunk_error}")
            print(f"    ğŸ”„ Using fallback descriptions for chunk {chunk_number}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª¬æ˜ã‚’ç”Ÿæˆ
            fallback_items = []
            for item in chunk:
                fallback_description = self.create_fallback_description(item)
                fallback_items.append({
                    "japanese_name": item.get("japanese_name", "N/A"),
                    "english_name": item.get("english_name", "N/A"),
                    "description": fallback_description,
                    "price": item.get("price", "")
                })
            
            return fallback_items
    
    def create_description_prompt(self, category: str, chunk: list) -> str:
        """è©³ç´°èª¬æ˜ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        return f"""ä»¥ä¸‹ã®ç¿»è¨³æ¸ˆã¿ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã«ã€å¤–å›½äººè¦³å…‰å®¢å‘ã‘ã®è©³ç´°èª¬æ˜ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª: {category}
é …ç›®æ•°: {len(chunk)}

ãƒ‡ãƒ¼ã‚¿:
{json.dumps({category: chunk}, ensure_ascii=False, indent=2)}

è¦ä»¶:
1. å„æ–™ç†ã«è©³ç´°ãªè‹±èªèª¬æ˜ã‚’è¿½åŠ 
2. èª¿ç†æ³•ã€ä½¿ç”¨é£Ÿæã€å‘³ã®ç‰¹å¾´ã‚’å«ã‚ã‚‹  
3. å¤–å›½äººãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨
4. æ–‡åŒ–çš„èƒŒæ™¯ã‚‚ç°¡æ½”ã«èª¬æ˜
5. è¦³å…‰å®¢å‘ã‘ã«é­…åŠ›çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã«ã™ã‚‹

å¿…ãšJSONå½¢å¼ã§è¿”ç­”ã—ã¦ãã ã•ã„:
{{
  "final_menu": {{
    "{category}": [
      {{
        "japanese_name": "æ—¥æœ¬èªå",
        "english_name": "è‹±èªå", 
        "description": "è©³ç´°ãªè‹±èªèª¬æ˜",
        "price": "ä¾¡æ ¼ï¼ˆã‚ã‚Œã°ï¼‰"
      }}
    ]
  }}
}}

å„èª¬æ˜ã¯30-80èªç¨‹åº¦ã§ã€æ–™ç†ã®ç‰¹å¾´ã¨é­…åŠ›ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚"""
    
    def extract_json_from_response(self, content: str) -> dict:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡º"""
        # JSONã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¢ã™
        json_start = content.find('{')
        json_end = content.rfind('}') + 1
        
        if json_start == -1 or json_end == -1:
            raise ValueError("No JSON found in response")
        
        json_str = content[json_start:json_end]
        return json.loads(json_str)
    
    def create_fallback_description(self, item: dict) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª¬æ˜ã‚’ä½œæˆ"""
        english_name = item.get("english_name", "Unknown dish")
        category = item.get("category", "dish")
        
        return f"Traditional Japanese {category.lower()} featuring {english_name} with authentic flavors and quality ingredients."
    
    def _get_error_type(self, error: Exception) -> str:
        """ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š"""
        error_str = str(error).lower()
        
        if "rate limit" in error_str:
            return "rate_limit_exceeded"
        elif "timeout" in error_str:
            return "api_timeout"
        elif "function call" in error_str:
            return "function_call_error"
        elif "connection" in error_str:
            return "connection_error"
        else:
            return "unknown_error"
    
    def _get_error_suggestions(self, error: Exception) -> List[str]:
        """ã‚¨ãƒ©ãƒ¼ã«å¯¾ã™ã‚‹æ”¹å–„ææ¡ˆã‚’å–å¾—"""
        error_type = self._get_error_type(error)
        
        suggestions_map = {
            "rate_limit_exceeded": [
                "Wait before retrying",
                "Check OpenAI API usage limits",
                "Consider upgrading your OpenAI plan"
            ],
            "api_timeout": [
                "Retry the request",
                "Check internet connectivity",
                "Try with shorter text input"
            ],
            "function_call_error": [
                "Check if the model supports function calling",
                "Verify the function schema is correct",
                "Try with a different model version"
            ],
            "connection_error": [
                "Check internet connectivity",
                "Verify OpenAI service status",
                "Try again in a few moments"
            ],
            "unknown_error": [
                "Check OPENAI_API_KEY is valid",
                "Verify model access permissions",
                "Check OpenAI service status"
            ]
        }
        
        return suggestions_map.get(error_type, suggestions_map["unknown_error"]) 