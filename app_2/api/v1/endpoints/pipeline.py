"""
Pipeline Endpoint - Enhanced Menu Processing with Staged Updates
OCRâ†’Mappingâ†’Categorizeå‡¦ç†ã®æ®µéšåˆ¥DBæ›´æ–°ã¨SSEé…ä¿¡å¯¾å¿œã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
"""
import uuid
from typing import Dict, Any
from fastapi import APIRouter, UploadFile, File, HTTPException, status, Query
from fastapi.responses import JSONResponse

from app_2.pipelines.pipeline_runner import get_menu_processing_pipeline
from app_2.utils.logger import get_logger

logger = get_logger("pipeline_endpoint")

router = APIRouter(prefix="/pipeline", tags=["pipeline"])


@router.post("/process", response_model=Dict[str, Any])
async def process_menu_image(
    file: UploadFile = File(..., description="ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”»åƒãƒ•ã‚¡ã‚¤ãƒ« (JPEG, PNG, WEBPå¯¾å¿œ)")
) -> JSONResponse:
    """
    ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”»åƒã®æ®µéšåˆ¥å‡¦ç†ï¼ˆEnhanced Pipelineï¼‰
    
    å„æ®µéšã§DBæ›´æ–°ã¨SSEé…ä¿¡ã‚’å®Ÿè¡Œ:
    1. OCRå‡¦ç† â†’ DBä¿å­˜ â†’ SSEé…ä¿¡ï¼ˆãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºçµæœï¼‰
    2. Mappingå‡¦ç† â†’ DBä¿å­˜ â†’ SSEé…ä¿¡ï¼ˆä½ç½®æƒ…å ±æ•´å½¢çµæœï¼‰
    3. Categorizeå‡¦ç† â†’ DBä¿å­˜ â†’ SSEé…ä¿¡ï¼ˆãƒ¡ãƒ‹ãƒ¥ãƒ¼æ§‹é€ ã¨ã‚¢ã‚¤ãƒ†ãƒ è¡¨ç¤ºï¼‰
    4. Parallel Tasksé–‹å§‹ï¼ˆç¿»è¨³ã€èª¬æ˜ã€ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼ã€ç”»åƒæ¤œç´¢ã€æˆåˆ†åˆ†æï¼‰
    
    Args:
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
        
    Returns:
        JSONResponse: å‡¦ç†çµæœ
        {
            "session_id": "uuid",
            "status": "success", 
            "processing_steps": {
                "step1_ocr": {"db_updated": true, "sse_broadcasted": true, ...},
                "step2_mapping": {"db_updated": true, "sse_broadcasted": true, ...},
                "step3_categorize": {"db_updated": true, "sse_broadcasted": true, ...},
                "step4_parallel_tasks": {"parallel_tasks_triggered": true}
            },
            "final_results": {...},
            "saved_menu_items": [...],
            "processing_time": 12.5,
            "message": "Enhanced Pipeline with realtime updates completed successfully"
        }
    
    SSEé…ä¿¡:
        ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ session_id ã‚’ä½¿ã£ã¦SSEãƒãƒ£ãƒ³ãƒãƒ«ã‚’è³¼èª­ã™ã‚‹ã¨ã€
        å„æ®µéšã®å®Œäº†æ™‚ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§çµæœã‚’å—ä¿¡ã§ãã¾ã™ã€‚
        
        ãƒãƒ£ãƒ³ãƒãƒ«: sse:{session_id}
        ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—:
        - stage_completed (OCRã€Mappingã€Categorizeå®Œäº†æ™‚)
        - progress_update (é€²æ—æ›´æ–°)
        - error (ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚)
    """
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³IDç”Ÿæˆ
    session_id = str(uuid.uuid4())
    
    try:
        logger.info(f"ğŸš€ Enhanced Pipeline processing started: session={session_id}, file={file.filename}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        if not file.content_type or not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Invalid file type: {file.content_type}. Only image files are supported."
            )
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        image_data = await file.read()
        
        if not image_data:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Empty file uploaded"
            )
        
        logger.info(f"ğŸ“Š Image loaded: {len(image_data)} bytes for enhanced pipeline processing")
        
        # Pipeline Runnerã«å‡¦ç†ã‚’å§”è­²ï¼ˆæ®µéšåˆ¥å‡¦ç†å¯¾å¿œç‰ˆï¼‰
        pipeline = get_menu_processing_pipeline()
        result = await pipeline.process_menu_image(
            session_id=session_id,
            image_data=image_data,
            filename=file.filename
        )
        
        # æ®µéšåˆ¥å‡¦ç†ã®çµæœãƒ­ã‚°
        processing_steps = result.get("processing_steps", {})
        logger.info(f"ğŸ“ˆ Enhanced Pipeline stages completed for session={session_id}:")
        
        for step_name, step_data in processing_steps.items():
            db_updated = step_data.get("db_updated", False)
            sse_broadcasted = step_data.get("sse_broadcasted", False)
            logger.info(f"  âœ“ {step_name}: DB={db_updated}, SSE={sse_broadcasted}")
        
        logger.info(f"âœ… Enhanced Pipeline processing completed: session={session_id}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«SSEæƒ…å ±ã‚’è¿½åŠ 
        result["sse_info"] = {
            "channel": f"sse:{session_id}",
            "connection_url": f"/api/v1/sse/stream/{session_id}",
            "message": "Connect to SSE for real-time updates"
        }
        
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Enhanced Pipeline processing failed: session={session_id}, error={e}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®çµ±ä¸€ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        error_response = {
            "session_id": session_id,
            "status": "error",
            "error": {
                "type": "processing_error",
                "message": str(e),
                "timestamp": "now"
            },
            "sse_info": {
                "channel": f"sse:{session_id}",
                "connection_url": f"/api/v1/sse/stream/{session_id}",
                "message": "Error details have been broadcasted via SSE"
            }
        }
        
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content=error_response
        )


@router.post("/process-with-session", response_model=Dict[str, Any])
async def process_menu_image_with_session(
    session_id: str = Query(..., description="ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ç”Ÿæˆã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ID"),
    file: UploadFile = File(..., description="ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”»åƒãƒ•ã‚¡ã‚¤ãƒ« (JPEG, PNG, WEBPå¯¾å¿œ)")
) -> JSONResponse:
    """
    æŒ‡å®šã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³IDã§ãƒ¡ãƒ‹ãƒ¥ãƒ¼ç”»åƒã‚’å‡¦ç†ï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰é€£æºç”¨ï¼‰
    
    Args:
        session_id: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§ç”Ÿæˆã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        file: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«
        
    Returns:
        JSONResponse: å‡¦ç†çµæœï¼ˆæ—¢å­˜ã®processã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨åŒã˜å½¢å¼ï¼‰
    """
    
    try:
        logger.info(f"ğŸš€ Enhanced Pipeline processing started with custom session: session={session_id}, file={file.filename}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
        if not file.content_type or not file.content_type.startswith('image/'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Invalid file type: {file.content_type}. Only image files are supported."
            )
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        image_data = await file.read()
        
        if not image_data:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Empty file uploaded"
            )
        
        logger.info(f"ğŸ“Š Image loaded: {len(image_data)} bytes for enhanced pipeline processing")
        
        # Pipeline Runnerã«å‡¦ç†ã‚’å§”è­²ï¼ˆã‚«ã‚¹ã‚¿ãƒ ã‚»ãƒƒã‚·ãƒ§ãƒ³IDä½¿ç”¨ï¼‰
        pipeline = get_menu_processing_pipeline()
        result = await pipeline.process_menu_image(
            session_id=session_id,  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã‚’ä½¿ç”¨
            image_data=image_data,
            filename=file.filename
        )
        
        # æ®µéšåˆ¥å‡¦ç†ã®çµæœãƒ­ã‚°
        processing_steps = result.get("processing_steps", {})
        logger.info(f"ğŸ“ˆ Enhanced Pipeline stages completed for custom session={session_id}:")
        
        for step_name, step_data in processing_steps.items():
            db_updated = step_data.get("db_updated", False)
            sse_broadcasted = step_data.get("sse_broadcasted", False)
            logger.info(f"  âœ“ {step_name}: DB={db_updated}, SSE={sse_broadcasted}")
        
        logger.info(f"âœ… Enhanced Pipeline processing completed: custom session={session_id}")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«SSEæƒ…å ±ã‚’è¿½åŠ 
        result["sse_info"] = {
            "channel": f"sse:{session_id}",
            "connection_url": f"/api/v1/sse/stream/{session_id}",
            "message": "Connect to SSE for real-time updates"
        }
        
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content=result
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Enhanced Pipeline processing failed: custom session={session_id}, error={e}")
        
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®çµ±ä¸€ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        error_response = {
            "session_id": session_id,
            "status": "error",
            "error": {
                "type": "processing_error",
                "message": str(e),
                "timestamp": "now"
            },
            "sse_info": {
                "channel": f"sse:{session_id}",
                "connection_url": f"/api/v1/sse/stream/{session_id}",
                "message": "Error details have been broadcasted via SSE"
            }
        }
        
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content=error_response
        )


@router.get("/health")
async def health_check() -> Dict[str, Any]:
    """
    Enhanced Pipelineã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    
    Returns:
        Dict: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
    """
    return {
        "status": "healthy",
        "service": "enhanced_pipeline",
        "version": "2.1.0",
        "architecture": "Staged Processing with Realtime Updates",
        "processing_stages": [
            "OCR (Text Extraction)",
            "Mapping (Position Formatting)", 
            "Categorize (Menu Structure Analysis)",
            "Parallel Tasks (Translation, Description, Allergen, Image Search, Ingredients)"
        ],
        "features": [
            "Stage-by-stage DB updates",
            "Real-time SSE broadcasting",
            "Progressive result display",
            "Parallel background processing"
        ],
        "sse_channels": "sse:{session_id}",
        "message": "Enhanced Pipeline: OCR â†’ Mapping â†’ Categorize with realtime DB updates and SSE broadcasts"
    }


@router.get("/session/{session_id}/status")
async def get_session_status(session_id: str) -> Dict[str, Any]:
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æ®µéšåˆ¥å‡¦ç†çŠ¶æ³ã‚’å–å¾—
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        
    Returns:
        Dict: ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ³
    """
    try:
        from app_2.core.database import async_session_factory
        from app_2.services.dependencies import get_session_repository
        
        async with async_session_factory() as db_session:
            session_repo = get_session_repository(db_session)
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥å–å¾—ã—ã¦æ®µéšãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
            from sqlalchemy import select
            from app_2.infrastructure.models.session_model import SessionModel
            
            stmt = select(SessionModel).where(SessionModel.session_id == session_id)
            result = await db_session.execute(stmt)
            session_model = result.scalar_one_or_none()
            
            if not session_model:
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail=f"Session not found: {session_id}"
                )
            
            # æ®µéšãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            stages_data = session_model.get_stages_data()
            
            return {
                "session_id": session_id,
                "status": session_model.status,
                "current_stage": session_model.current_stage,
                "stages_completed": list(stages_data.keys()),
                "stages_data": stages_data,
                "created_at": session_model.created_at.isoformat(),
                "updated_at": session_model.updated_at.isoformat(),
                "menu_ids": session_model.menu_ids
            }
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get session status {session_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to retrieve session status: {str(e)}"
        ) 