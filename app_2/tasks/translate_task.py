"""
Translation Task - Menu Processor v2 (Refactored with BatchProcessor)
ç¿»è¨³å‡¦ç†ã‚’æ‹…å½“ã™ã‚‹Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
"""
import asyncio
import uuid
from typing import Dict, List, Any
import redis.asyncio as redis

from app_2.core.celery_app import celery_app
from app_2.tasks.batch_processor import BatchProcessor, BatchConfig
from app_2.services.translate_service import get_translate_service
from app_2.infrastructure.repositories.menu_repository_impl import MenuRepositoryImpl
from app_2.core.database import async_session_factory
from app_2.core.config import settings
from app_2.utils.logger import get_logger

logger = get_logger("translate_task")


@celery_app.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3}, queue='translation_queue')
def translate_menu_task(
    self, 
    session_id: str, 
    menu_items: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã®ç¿»è¨³å‡¦ç†ã‚¿ã‚¹ã‚¯ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        menu_items: ç¿»è¨³å¯¾è±¡ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆï¼ˆå®Ÿéš›ã®entityã‹ã‚‰å¤‰æ›ã•ã‚ŒãŸdictï¼‰
        
    Returns:
        Dict[str, Any]: å‡¦ç†çµæœ
    """
    # éåŒæœŸå‡¦ç†ã‚’ãƒ©ãƒƒãƒ—ã—ã¦å®Ÿè¡Œ
    return asyncio.run(_translate_menu_task_async(self, session_id, menu_items))


async def _translate_menu_task_async(
    task_instance,
    session_id: str, 
    menu_items: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã®ç¿»è¨³å‡¦ç†ã‚¿ã‚¹ã‚¯ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        menu_items: ç¿»è¨³å¯¾è±¡ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆ
        
    Returns:
        Dict[str, Any]: å‡¦ç†çµæœ
    """
    task_id = task_instance.request.id
    total_items = len(menu_items)
    
    logger.info(f"Translation task started: session={session_id}, items={total_items}, task_id={task_id}")
    
    try:
        # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼è¨­å®š
        config = BatchConfig(
            batch_size=10,
            max_concurrent_batches=2, 
            task_name="translation"
        )
        
        processor = BatchProcessor(config)
        translate_service = get_translate_service()
        
        # ç¿»è¨³å‡¦ç†é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        async def translation_processor(item: Dict[str, Any]) -> Dict[str, Any]:
            """ç¿»è¨³å›ºæœ‰ã®å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯"""
            menu_name = item.get("name", "")
            category = item.get("category", "")
            
            # ç¿»è¨³å‡¦ç†ã‚’å®Ÿè¡Œ
            translated_data = await translate_service.translate_menu_data(
                {"name": menu_name, "category": category},
                target_language="en"  # è‹±èªã«ç¿»è¨³
            )
            
            return translated_data
        
        # ğŸ”¥ å®Œå…¨åˆ†é›¢å‹DBæ›´æ–°é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯å°‚ç”¨Redisæ¥ç¶šï¼‰
        async def translation_db_updater(item_id: str, translated_data: Dict[str, Any]) -> bool:
            """ç¿»è¨³çµæœã‚’DBã«æ›´æ–°ï¼ˆå®Œå…¨åˆ†é›¢å‹Redisï¼‰"""
            # ğŸ”¥ ã‚¿ã‚¹ã‚¯å°‚ç”¨Redisæ¥ç¶šã‚’ä½œæˆï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãªã—ï¼‰
            task_redis = None
            try:
                task_redis = redis.from_url(
                    settings.celery.redis_url,
                    decode_responses=True,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
                
                # åˆ†æ•£ãƒ­ãƒƒã‚¯å‡¦ç†
                lock_key = f"lock:menu_update:translation:{item_id}"
                lock_value = str(uuid.uuid4())
                
                # ãƒ­ãƒƒã‚¯å–å¾—è©¦è¡Œï¼ˆ10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                acquired = await task_redis.set(lock_key, lock_value, ex=10, nx=True)
                if not acquired:
                    logger.error(f"Failed to acquire lock for translation update: {item_id}")
                    return False
                
                try:
                    # ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ä»˜ãDBæ›´æ–°
                    for retry_count in range(3):
                        try:
                            async with async_session_factory() as db_session:
                                menu_repository = MenuRepositoryImpl(db_session)
                                
                                # ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                                translation_text = translated_data.get("name", "")
                                category_translation = translated_data.get("category", "")
                                
                                # éƒ¨åˆ†æ›´æ–°ã‚’ä½¿ç”¨ï¼ˆç¿»è¨³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿æ›´æ–°ï¼‰
                                update_fields = {
                                    "translation": translation_text,
                                    "category_translation": category_translation
                                }
                                
                                updated_entity = await menu_repository.update_partial(item_id, update_fields)
                                
                                if updated_entity:
                                    logger.info(f"Translation DB update successful: {item_id}")
                                    return True
                                else:
                                    if retry_count < 2:
                                        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å°‘ã—å¾…ã£ã¦ãƒªãƒˆãƒ©ã‚¤
                                        logger.warning(f"Menu entity not found for {item_id}, retrying... ({retry_count + 1}/3)")
                                        await asyncio.sleep(0.5 * (retry_count + 1))
                                        continue
                                    else:
                                        logger.error(f"Menu entity not found for translation update after 3 retries: {item_id}")
                                        return False
                            
                        except Exception as e:
                            if retry_count < 2:
                                logger.warning(f"Translation DB update failed for {item_id}, retrying... ({retry_count + 1}/3): {e}")
                                await asyncio.sleep(0.5 * (retry_count + 1))
                                continue
                            else:
                                logger.error(f"Translation DB update failed for {item_id} after 3 retries: {e}")
                                return False
                    
                    return False
                    
                finally:
                    # ğŸ”¥ åŸå­çš„ãƒ­ãƒƒã‚¯è§£æ”¾ï¼ˆLuaã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰
                    lua_script = """
                    if redis.call("get", KEYS[1]) == ARGV[1] then
                        return redis.call("del", KEYS[1])
                    else
                        return 0
                    end
                    """
                    try:
                        await task_redis.eval(lua_script, 1, lock_key, lock_value)
                    except Exception as e:
                        logger.warning(f"Failed to release lock {lock_key}: {e}")
                
            except Exception as e:
                logger.error(f"Redis connection error for translation update {item_id}: {e}")
                return False
            finally:
                # ğŸ”¥ ç¢ºå®Ÿã«Redisæ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if task_redis:
                    try:
                        await task_redis.aclose()
                    except Exception as e:
                        logger.warning(f"Redis cleanup error: {e}")
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        result = await processor.process_items(
            session_id=session_id,
            items=menu_items,
            processor_func=translation_processor,
            db_updater_func=translation_db_updater
        )
        
        # ã‚¿ã‚¹ã‚¯IDã‚’çµæœã«è¿½åŠ 
        result["task_id"] = task_id
        
        # ğŸ¯ ç¿»è¨³ã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã®è©³ç´°SSEé€ä¿¡
        if result.get("status") == "success":
            from app_2.infrastructure.integrations.redis.redis_publisher import RedisPublisher
            redis_publisher = RedisPublisher()
            
            # ç¿»è¨³å®Œäº†ã®è©³ç´°é€šçŸ¥ã‚’é€ä¿¡
            await redis_publisher.publish_session_message(
                session_id=session_id,
                message_type="translation_batch_completed",
                data={
                    "task_type": "translation",
                    "batch_status": "completed",
                    "completed_items": result.get("completed_items", 0),
                    "total_items": result.get("total_items", 0),
                    "success_rate": result.get("success_rate", 0),
                    "task_id": task_id,
                    "processing_summary": {
                        "items_processed": len(menu_items),
                        "source_language": "Japanese",
                        "target_language": "English",
                        "batch_completed_at": "now",
                        "translation_provider": "Google Translate"
                    },
                    "message": f"Translation completed: {result.get('completed_items', 0)}/{result.get('total_items', 0)} items now have English translations"
                }
            )
            
            logger.info(f"ğŸŒ Translation batch completion broadcasted for session: {session_id}")
        
        logger.info(f"Translation task completed successfully: {result}")
        return result
        
    except Exception as e:
        logger.error(f"Translation task failed: {e}", extra={
            "session_id": session_id,
            "task_id": task_id,
            "input_count": total_items
        })
        raise 