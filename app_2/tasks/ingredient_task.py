"""
Ingredient Task - Menu Processor v2 (Refactored with BatchProcessor)
å†…å®¹ç‰©è§£æå‡¦ç†ã‚’æ‹…å½“ã™ã‚‹Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
"""
import asyncio
import uuid
from typing import Dict, List, Any
import redis.asyncio as redis

from app_2.core.celery_app import celery_app
from app_2.tasks.batch_processor import BatchProcessor, BatchConfig
from app_2.services.ingredient_service import get_ingredient_service
from app_2.infrastructure.repositories.menu_repository_impl import MenuRepositoryImpl
from app_2.core.database import async_session_factory
from app_2.core.config import settings
from app_2.utils.logger import get_logger

logger = get_logger("ingredient_task")


@celery_app.task(bind=True, autoretry_for=(Exception,), retry_kwargs={'max_retries': 3}, queue='ingredient_queue')
def ingredient_menu_task(
    self, 
    session_id: str, 
    menu_items: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã®å†…å®¹ç‰©è§£æå‡¦ç†ã‚¿ã‚¹ã‚¯ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        menu_items: å†…å®¹ç‰©è§£æå¯¾è±¡ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆï¼ˆå®Ÿéš›ã®entityã‹ã‚‰å¤‰æ›ã•ã‚ŒãŸdictï¼‰
        
    Returns:
        Dict[str, Any]: å‡¦ç†çµæœ
    """
    # éåŒæœŸå‡¦ç†ã‚’ãƒ©ãƒƒãƒ—ã—ã¦å®Ÿè¡Œ
    return asyncio.run(_ingredient_menu_task_async(self, session_id, menu_items))


async def _ingredient_menu_task_async(
    task_instance,
    session_id: str, 
    menu_items: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """
    ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã®å†…å®¹ç‰©è§£æå‡¦ç†ã‚¿ã‚¹ã‚¯ï¼ˆBatchProcessorä½¿ç”¨ç‰ˆï¼‰
    
    Args:
        session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³ID
        menu_items: å†…å®¹ç‰©è§£æå¯¾è±¡ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚¢ã‚¤ãƒ†ãƒ ãƒªã‚¹ãƒˆ
        
    Returns:
        Dict[str, Any]: å‡¦ç†çµæœ
    """
    task_id = task_instance.request.id
    total_items = len(menu_items)
    
    logger.info(f"Ingredient task started: session={session_id}, items={total_items}, task_id={task_id}")
    
    try:
        # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼è¨­å®š
        config = BatchConfig(
            batch_size=8,
            max_concurrent_batches=3, 
            task_name="ingredient"
        )
        
        processor = BatchProcessor(config)
        ingredient_service = get_ingredient_service()
        
        # å†…å®¹ç‰©è§£æå‡¦ç†é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯å›ºæœ‰ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        async def ingredient_processor(item: Dict[str, Any]) -> Dict[str, Any]:
            """å†…å®¹ç‰©è§£æå›ºæœ‰ã®å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯"""
            menu_name = item.get("name", "")
            category = item.get("category", "")
            
            # ç¿»è¨³æ¸ˆã¿ã®åå‰ãŒã‚ã‚Œã°ã€ãã‚Œã‚‚ä½µç”¨
            translation = item.get("translation", "")
            if translation:
                # ç¿»è¨³ã¨åŸæ–‡ã®ä¸¡æ–¹ã‚’ä½¿ã£ã¦å†…å®¹ç‰©è§£æã‚’å®Ÿè¡Œ
                ingredient_input = f"{menu_name} ({translation})"
            else:
                ingredient_input = menu_name
            
            return await ingredient_service.analyze_ingredients(
                menu_item=ingredient_input, 
                category=category
            )
        
        # ğŸ”¥ å®Œå…¨åˆ†é›¢å‹DBæ›´æ–°é–¢æ•°ï¼ˆã‚¿ã‚¹ã‚¯å°‚ç”¨Redisæ¥ç¶šï¼‰
        async def ingredient_db_updater(item_id: str, ingredient_data: Dict[str, Any]) -> bool:
            """å†…å®¹ç‰©è§£æçµæœã‚’DBã«æ›´æ–°ï¼ˆå®Œå…¨åˆ†é›¢å‹Redisï¼‰"""
            # ğŸ”¥ ã‚¿ã‚¹ã‚¯å°‚ç”¨Redisæ¥ç¶šã‚’ä½œæˆï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãªã—ï¼‰
            task_redis = None
            try:
                task_redis = redis.from_url(
                    settings.celery.redis_url,
                    decode_responses=True,
                    socket_connect_timeout=5,
                    socket_timeout=5
                )
                
                # åˆ†æ•£ãƒ­ãƒƒã‚¯å‡¦ç†
                lock_key = f"lock:menu_update:ingredient:{item_id}"
                lock_value = str(uuid.uuid4())
                
                # ãƒ­ãƒƒã‚¯å–å¾—è©¦è¡Œï¼ˆ10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
                acquired = await task_redis.set(lock_key, lock_value, ex=10, nx=True)
                if not acquired:
                    logger.error(f"Failed to acquire lock for ingredient update: {item_id}")
                    return False
                
                try:
                    # ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹ä»˜ãDBæ›´æ–°
                    for retry_count in range(3):
                        try:
                            async with async_session_factory() as db_session:
                                menu_repository = MenuRepositoryImpl(db_session)
                                
                                # å†…å®¹ç‰©è§£æãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                                main_ingredients = ingredient_data.get("main_ingredients", [])
                                if main_ingredients:
                                    # ä¸»è¦ææ–™ãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
                                    ingredient_text = ", ".join([ing.get("ingredient", ing) if isinstance(ing, dict) else str(ing) for ing in main_ingredients])
                                else:
                                    # å†…å®¹ç‰©æƒ…å ±ãŒãªã„å ´åˆã®å¯¾å¿œ
                                    cuisine_category = ingredient_data.get("cuisine_category", "")
                                    cooking_method = ingredient_data.get("cooking_method", [])
                                    if cuisine_category != "unknown":
                                        ingredient_text = f"æ–™ç†ã‚¿ã‚¤ãƒ—: {cuisine_category}"
                                    elif cooking_method:
                                        ingredient_text = f"èª¿ç†æ³•: {', '.join(cooking_method)}"
                                    else:
                                        ingredient_text = "ææ–™æƒ…å ±ä¸æ˜"
                                
                                # éƒ¨åˆ†æ›´æ–°ã‚’ä½¿ç”¨ï¼ˆå†…å®¹ç‰©ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿æ›´æ–°ï¼‰
                                update_fields = {
                                    "ingredient": ingredient_text
                                }
                                
                                updated_entity = await menu_repository.update_partial(item_id, update_fields)
                                
                                if updated_entity:
                                    logger.info(f"Ingredient DB update successful: {item_id}")
                                    return True
                                else:
                                    if retry_count < 2:
                                        # ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€å°‘ã—å¾…ã£ã¦ãƒªãƒˆãƒ©ã‚¤
                                        logger.warning(f"Menu entity not found for {item_id}, retrying... ({retry_count + 1}/3)")
                                        await asyncio.sleep(0.5 * (retry_count + 1))
                                        continue
                                    else:
                                        logger.error(f"Menu entity not found for ingredient update after 3 retries: {item_id}")
                                        return False
                            
                        except Exception as e:
                            if retry_count < 2:
                                logger.warning(f"Ingredient DB update failed for {item_id}, retrying... ({retry_count + 1}/3): {e}")
                                await asyncio.sleep(0.5 * (retry_count + 1))
                                continue
                            else:
                                logger.error(f"Ingredient DB update failed for {item_id} after 3 retries: {e}")
                                return False
                    
                    return False
                    
                finally:
                    # ğŸ”¥ åŸå­çš„ãƒ­ãƒƒã‚¯è§£æ”¾ï¼ˆLuaã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰
                    lua_script = """
                    if redis.call("get", KEYS[1]) == ARGV[1] then
                        return redis.call("del", KEYS[1])
                    else
                        return 0
                    end
                    """
                    try:
                        await task_redis.eval(lua_script, 1, lock_key, lock_value)
                    except Exception as e:
                        logger.warning(f"Failed to release lock {lock_key}: {e}")
                
            except Exception as e:
                logger.error(f"Redis connection error for ingredient update {item_id}: {e}")
                return False
            finally:
                # ğŸ”¥ ç¢ºå®Ÿã«Redisæ¥ç¶šã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                if task_redis:
                    try:
                        await task_redis.aclose()
                    except Exception as e:
                        logger.warning(f"Redis cleanup error: {e}")
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        result = await processor.process_items(
            session_id=session_id,
            items=menu_items,
            processor_func=ingredient_processor,
            db_updater_func=ingredient_db_updater
        )
        
        # ã‚¿ã‚¹ã‚¯IDã‚’çµæœã«è¿½åŠ 
        result["task_id"] = task_id
        
        # ğŸ¯ å†…å®¹ç‰©è§£æã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã®è©³ç´°SSEé€ä¿¡
        if result.get("status") == "success":
            from app_2.infrastructure.integrations.redis.redis_publisher import RedisPublisher
            redis_publisher = RedisPublisher()
            
            # å†…å®¹ç‰©è§£æå®Œäº†ã®è©³ç´°é€šçŸ¥ã‚’é€ä¿¡
            await redis_publisher.publish_session_message(
                session_id=session_id,
                message_type="ingredient_batch_completed",
                data={
                    "task_type": "ingredient",
                    "batch_status": "completed",
                    "completed_items": result.get("completed_items", 0),
                    "total_items": result.get("total_items", 0),
                    "success_rate": result.get("success_rate", 0),
                    "task_id": task_id,
                    "processing_summary": {
                        "items_processed": len(menu_items),
                        "analysis_language": "Japanese/English",
                        "batch_completed_at": "now",
                        "nutrition_info": "ingredient_analysis_completed"
                    },
                    "message": f"Ingredient analysis completed: {result.get('completed_items', 0)}/{result.get('total_items', 0)} items now have ingredient information"
                }
            )
            
            logger.info(f"ğŸ¥¬ Ingredient batch completion broadcasted for session: {session_id}")
        
        logger.info(f"Ingredient task completed successfully: {result}")
        return result
        
    except Exception as e:
        logger.error(f"Ingredient task failed: {e}", extra={
            "session_id": session_id,
            "task_id": task_id,
            "input_count": total_items
        })
        raise 