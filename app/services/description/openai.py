import json
import asyncio
from typing import Optional

try:
    import openai
    from openai import AsyncOpenAI
except ImportError:
    openai = None
    AsyncOpenAI = None

from app.core.config import settings
from .base import BaseDescriptionService, DescriptionResult, DescriptionProvider

class OpenAIDescriptionService(BaseDescriptionService):
    """OpenAI APIã‚’ä½¿ç”¨ã—ãŸè©³ç´°èª¬æ˜ç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        super().__init__()
        self.provider = DescriptionProvider.OPENAI
        self.client = None
        self._initialize_client()
    
    def _initialize_client(self):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            if not openai or not AsyncOpenAI:
                print("âŒ openai package not installed. Install with: pip install openai")
                return
                
            if settings.OPENAI_API_KEY:
                self.client = AsyncOpenAI(
                    api_key=settings.OPENAI_API_KEY,
                    timeout=settings.OPENAI_TIMEOUT,
                    max_retries=settings.OPENAI_MAX_RETRIES
                )
                print("ğŸ”§ OpenAI Description Service initialized successfully")
            else:
                print("âš ï¸ OPENAI_API_KEY not set")
                
        except Exception as e:
            print(f"âŒ Failed to initialize OpenAI Description Service: {e}")
            self.client = None
    
    def is_available(self) -> bool:
        """ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return self.client is not None and bool(settings.OPENAI_API_KEY)
    
    async def call_openai_with_retry(self, messages, max_retries=2):
        """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ãã§OpenAI APIã‚’å‘¼ã³å‡ºã™ãƒªãƒˆãƒ©ã‚¤é–¢æ•°ï¼ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†ç”¨ï¼‰"""
        if not self.is_available():
            raise Exception("OpenAI API is not available")
        
        for attempt in range(max_retries + 1):
            try:
                response = await self.client.chat.completions.create(
                    model=settings.OPENAI_MODEL,
                    messages=messages
                )
                return response
                
            except openai.RateLimitError as e:
                if attempt == max_retries:
                    raise Exception(f"Rate limit exceeded after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = settings.RETRY_BASE_DELAY ** attempt
                print(f"â³ Rate limit hit, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                await asyncio.sleep(wait_time)
                
            except openai.APITimeoutError as e:
                if attempt == max_retries:
                    raise Exception(f"API timeout after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = settings.RETRY_BASE_DELAY ** attempt
                print(f"â³ API timeout, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                await asyncio.sleep(wait_time)
                
            except openai.APIConnectionError as e:
                if attempt == max_retries:
                    raise Exception(f"API connection error after {max_retries + 1} attempts: {str(e)}")
                
                wait_time = settings.RETRY_BASE_DELAY ** attempt
                print(f"â³ Connection error, waiting {wait_time} seconds before retry {attempt + 1}/{max_retries}")
                await asyncio.sleep(wait_time)
                
            except Exception as e:
                # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«å¤±æ•—
                raise Exception(f"OpenAI API error: {str(e)}")
    
    def create_description_prompt(self, category: str, chunk: list) -> str:
        """è©³ç´°èª¬æ˜ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        example_descriptions = self.get_example_descriptions()
        examples_text = "\n".join([
            f"- \"{dish}\" â†’ \"{desc}\""
            for dish, desc in list(example_descriptions.items())[:3]
        ])
        
        return f"""ä»¥ä¸‹ã®ç¿»è¨³æ¸ˆã¿ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã«ã€å¤–å›½äººè¦³å…‰å®¢å‘ã‘ã®è©³ç´°èª¬æ˜ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

ã‚«ãƒ†ã‚´ãƒª: {category}
é …ç›®æ•°: {len(chunk)}

ãƒ‡ãƒ¼ã‚¿:
{json.dumps({category: chunk}, ensure_ascii=False, indent=2)}

è¦ä»¶:
1. å„æ–™ç†ã«è©³ç´°ãªè‹±èªèª¬æ˜ã‚’è¿½åŠ 
2. èª¿ç†æ³•ã€ä½¿ç”¨é£Ÿæã€å‘³ã®ç‰¹å¾´ã‚’å«ã‚ã‚‹  
3. å¤–å›½äººãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’ä½¿ç”¨
4. æ–‡åŒ–çš„èƒŒæ™¯ã‚‚ç°¡æ½”ã«èª¬æ˜
5. è¦³å…‰å®¢å‘ã‘ã«é­…åŠ›çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã«ã™ã‚‹

å¿…ãšJSONå½¢å¼ã§è¿”ç­”ã—ã¦ãã ã•ã„:
{{
  "final_menu": {{
    "{category}": [
      {{
        "japanese_name": "æ—¥æœ¬èªå",
        "english_name": "è‹±èªå", 
        "description": "è©³ç´°ãªè‹±èªèª¬æ˜",
        "price": "ä¾¡æ ¼ï¼ˆã‚ã‚Œã°ï¼‰"
      }}
    ]
  }}
}}

ä¾‹ã®èª¬æ˜:
{examples_text}

å„èª¬æ˜ã¯30-80èªç¨‹åº¦ã§ã€æ–™ç†ã®ç‰¹å¾´ã¨é­…åŠ›ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚"""
    
    def extract_json_from_response(self, content: str) -> dict:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡º"""
        # JSONã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¢ã™
        json_start = content.find('{')
        json_end = content.rfind('}') + 1
        
        if json_start == -1 or json_end == -1:
            raise ValueError("No JSON found in response")
        
        json_str = content[json_start:json_end]
        return json.loads(json_str)
    
    async def process_chunk(
        self, 
        category: str, 
        chunk: list, 
        chunk_number: int, 
        total_chunks: int,
        session_id: Optional[str] = None
    ) -> list:
        """ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ã—ã¦è©³ç´°èª¬æ˜ã‚’è¿½åŠ """
        print(f"  ğŸ“¦ Processing chunk {chunk_number}/{total_chunks} ({len(chunk)} items)")
        
        # é€²è¡ŒçŠ¶æ³é€šçŸ¥ï¼ˆãƒãƒ£ãƒ³ã‚¯å‡¦ç†ä¸­ï¼‰
        if session_id:
            from app.main import send_progress
            await send_progress(
                session_id, 4, "active", 
                f"ğŸ”„ Processing {category} (part {chunk_number}/{total_chunks})",
                {"chunk_progress": f"{chunk_number}/{total_chunks}"}
            )
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
            messages = [
                {
                    "role": "user",
                    "content": self.create_description_prompt(category, chunk)
                }
            ]
            
            # OpenAI APIå‘¼ã³å‡ºã—
            response = await self.call_openai_with_retry(messages, max_retries=2)
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰JSONã‚’æŠ½å‡º
            content = response.choices[0].message.content
            chunk_result = self.extract_json_from_response(content)
            
            if 'final_menu' in chunk_result and category in chunk_result['final_menu']:
                new_items = chunk_result['final_menu'][category]
                
                # èª¬æ˜ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for item in new_items:
                    if item.get("description"):
                        item["description"] = self.clean_description_text(item["description"])
                
                print(f"    âœ… Successfully processed {len(new_items)} items in chunk")
                return new_items
            else:
                raise ValueError("Invalid response format")
                
        except Exception as chunk_error:
            print(f"âš ï¸ Chunk processing error: {chunk_error}")
            print(f"    ğŸ”„ Using fallback descriptions for chunk {chunk_number}")
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯èª¬æ˜ã‚’ç”Ÿæˆ
            fallback_items = []
            for item in chunk:
                fallback_description = self.create_fallback_description(item)
                fallback_items.append({
                    "japanese_name": item.get("japanese_name", "N/A"),
                    "english_name": item.get("english_name", "N/A"),
                    "description": fallback_description,
                    "price": item.get("price", "")
                })
            
            return fallback_items
    
    async def add_descriptions(
        self, 
        translated_data: dict, 
        session_id: Optional[str] = None
    ) -> DescriptionResult:
        """
        ç¿»è¨³ã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«è©³ç´°èª¬æ˜ã‚’è¿½åŠ ï¼ˆåˆ†å‰²å‡¦ç†ç‰ˆï¼‰
        
        Args:
            translated_data: ç¿»è¨³ã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿
            session_id: ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆé€²è¡ŒçŠ¶æ³é€šçŸ¥ç”¨ï¼‰
            
        Returns:
            DescriptionResult: è©³ç´°èª¬æ˜ç”Ÿæˆçµæœ
        """
        print("ğŸ“ Starting detailed description generation with OpenAI (Chunked Processing)...")
        
        # ã‚µãƒ¼ãƒ“ã‚¹åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
        if not self.is_available():
            return DescriptionResult(
                success=False,
                description_method="openai",
                error="OpenAI API is not available",
                metadata={
                    "error_type": "service_unavailable",
                    "suggestions": [
                        "Set OPENAI_API_KEY environment variable",
                        "Install openai package: pip install openai",
                        "Check OpenAI API access permissions",
                        "Verify internet connectivity"
                    ]
                }
            )
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        if not self.validate_translated_data(translated_data):
            return DescriptionResult(
                success=False,
                description_method="openai",
                error="Invalid translated data",
                metadata={
                    "error_type": "invalid_input",
                    "suggestions": [
                        "Provide valid translated menu data",
                        "Ensure at least one category has menu items",
                        "Check translated data structure format"
                    ]
                }
            )
        
        try:
            final_menu = {}
            total_items = sum(len(items) for items in translated_data.values())
            processed_items = 0
            
            print(f"ğŸ”¢ Total items to process: {total_items}")
            
            # ã‚«ãƒ†ã‚´ãƒªã”ã¨ã«å‡¦ç†
            for category, items in translated_data.items():
                if not items:
                    final_menu[category] = []
                    continue
                    
                print(f"ğŸ”„ Processing category: {category} ({len(items)} items)")
                
                # é€²è¡ŒçŠ¶æ³é€šçŸ¥ï¼ˆã‚«ãƒ†ã‚´ãƒªé–‹å§‹ï¼‰
                if session_id:
                    from app.main import send_progress
                    await send_progress(
                        session_id, 4, "active", 
                        f"ğŸ½ï¸ Adding descriptions for {category}...",
                        {"processing_category": category, "total_categories": len(translated_data)}
                    )
                
                # å¤§ããªã‚«ãƒ†ã‚´ãƒªã¯åˆ†å‰²å‡¦ç†
                chunk_size = settings.PROCESSING_CHUNK_SIZE
                category_results = []
                
                for i in range(0, len(items), chunk_size):
                    chunk = items[i:i + chunk_size]
                    chunk_number = (i // chunk_size) + 1
                    total_chunks = (len(items) + chunk_size - 1) // chunk_size
                    
                    # ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
                    new_items = await self.process_chunk(
                        category, chunk, chunk_number, total_chunks, session_id
                    )
                    
                    category_results.extend(new_items)
                    processed_items += len(chunk)
                    
                    # é€²æ—æ›´æ–°ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
                    if session_id:
                        progress_percent = int((processed_items / total_items) * 100)
                        
                        await send_progress(
                            session_id, 4, "active", 
                            f"ğŸ½ï¸ {category}: ãƒãƒ£ãƒ³ã‚¯{chunk_number}/{total_chunks}å®Œäº† ({len(new_items)}ã‚¢ã‚¤ãƒ†ãƒ è¿½åŠ )",
                            {
                                "progress_percent": progress_percent,
                                "processing_category": category,
                                "partial_results": {category: category_results},  # ç´¯ç©çµæœ
                                "newly_processed_items": new_items,   # æ–°ã—ãå‡¦ç†ã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ 
                                "chunk_completed": f"{chunk_number}/{total_chunks}",
                                "chunk_size": len(chunk),
                                "items_in_category": len(category_results),
                                "streaming_update": True  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ›´æ–°ãƒ•ãƒ©ã‚°
                            }
                        )
                    
                    # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã¨ã—ã¦å°‘ã—å¾…æ©Ÿ
                    await asyncio.sleep(settings.RATE_LIMIT_SLEEP)
                
                final_menu[category] = category_results
                
                # ã‚«ãƒ†ã‚´ãƒªå®Œäº†é€šçŸ¥ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¼·åŒ–ï¼‰
                if session_id:
                    await send_progress(
                        session_id, 4, "active", 
                        f"âœ… {category}ã‚«ãƒ†ã‚´ãƒªå®Œäº†ï¼{len(category_results)}ã‚¢ã‚¤ãƒ†ãƒ ã®è©³ç´°èª¬æ˜ã‚’è¿½åŠ ã—ã¾ã—ãŸ",
                        {
                            "category_completed": category,
                            "category_items": len(category_results),
                            "partial_menu": final_menu,  # å…¨ä½“ã®ç´¯ç©çµæœ
                            "completed_category_items": category_results,  # å®Œäº†ã—ãŸã‚«ãƒ†ã‚´ãƒªã®ã‚¢ã‚¤ãƒ†ãƒ è©³ç´°
                            "category_completion": True,  # ã‚«ãƒ†ã‚´ãƒªå®Œäº†ãƒ•ãƒ©ã‚°
                            "remaining_categories": [cat for cat in translated_data.keys() if cat not in final_menu]
                        }
                    )
                
                print(f"âœ… Category '{category}' completed: {len(category_results)} items")
            
            print(f"ğŸ‰ OpenAI Description Generation Complete: Added descriptions to {len(final_menu)} categories, {total_items} total items")
            
            # å‡¦ç†çµ±è¨ˆã‚’ç”Ÿæˆ
            statistics = self.extract_processing_statistics(translated_data, final_menu)
            
            return DescriptionResult(
                success=True,
                final_menu=final_menu,
                description_method="openai",
                metadata={
                    "total_items": total_items,
                    "categories_processed": len(final_menu),
                    "provider": "OpenAI API",
                    "model": settings.OPENAI_MODEL,
                    "features": [
                        "chunked_processing",
                        "detailed_descriptions",
                        "cultural_context",
                        "tourist_friendly_language",
                        "real_time_progress"
                    ],
                    "processing_statistics": statistics
                }
            )
            
        except Exception as e:
            print(f"âŒ OpenAI Description Generation Failed: {e}")
            
            # ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—ã®åˆ¤å®š
            error_type = "unknown_error"
            suggestions = []
            
            if "rate limit" in str(e).lower():
                error_type = "rate_limit_exceeded"
                suggestions = [
                    "Wait before retrying",
                    "Check OpenAI API usage limits",
                    "Consider upgrading your OpenAI plan",
                    "Try processing smaller chunks"
                ]
            elif "timeout" in str(e).lower():
                error_type = "api_timeout"
                suggestions = [
                    "Retry the request",
                    "Check internet connectivity",
                    "Try with smaller menu chunks",
                    "Increase timeout settings"
                ]
            elif "json" in str(e).lower() or "parse" in str(e).lower():
                error_type = "response_parsing_error"
                suggestions = [
                    "OpenAI response format was unexpected",
                    "Try with different model settings",
                    "Check if the model supports the request format"
                ]
            else:
                suggestions = [
                    "Check OPENAI_API_KEY is valid",
                    "Verify model access permissions",
                    "Check OpenAI service status",
                    "Ensure input data is properly formatted"
                ]
            
            return DescriptionResult(
                success=False,
                description_method="openai",
                error=f"OpenAI description generation error: {str(e)}",
                metadata={
                    "error_type": error_type,
                    "original_error": str(e),
                    "suggestions": suggestions,
                    "provider": "OpenAI API",
                    "model": settings.OPENAI_MODEL,
                    "processed_items": processed_items if 'processed_items' in locals() else 0,
                    "total_items": sum(len(items) for items in translated_data.values())
                }
            )
