"""
ãƒ¡ãƒ‹ãƒ¥ãƒ¼å‡¦ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å„Stageé–¢æ•°

å„Stageã®è²¬å‹™ï¼š
- Stage 1: OCRï¼ˆç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºï¼‰
- Stage 2: ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆæ—¥æœ¬èªãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®åˆ†é¡ï¼‰
- Stage 3: ç¿»è¨³ï¼ˆæ—¥æœ¬èªâ†’è‹±èªï¼‰
- Stage 4: è©³ç´°èª¬æ˜è¿½åŠ 
- Stage 5: ç”»åƒç”Ÿæˆ
"""
import asyncio

# ã‚µãƒ¼ãƒ“ã‚¹å±¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from app.services.ocr import extract_text as ocr_extract_text
from app.services.category import categorize_menu as category_categorize_menu
from app.services.translation import translate_menu as translation_translate_menu
from app.services.description import add_descriptions as description_add_descriptions
from app.services.image import generate_images as image_generate_images

# ä¾å­˜é–¢æ•°ã®å–å¾—ï¼ˆå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ï¼‰
def get_progress_function():
    """send_progressé–¢æ•°ã‚’å–å¾—ï¼ˆå¾ªç’°ã‚¤ãƒ³ãƒãƒ¼ãƒˆå›é¿ï¼‰"""
    try:
        from app.services.realtime import send_progress
        return send_progress
    except ImportError:
        return None

# Stage 1: OCRä¸¦åˆ—å‡¦ç†ç‰ˆ
async def stage1_ocr_gemini_exclusive(image_path: str, session_id: str = None) -> dict:
    """Stage 1: ä¸¦åˆ—OCRã§é«˜ç²¾åº¦ãƒ»é«˜é€ŸåŒ–ï¼ˆãƒãƒ«ãƒã‚¨ãƒ³ã‚¸ãƒ³ + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    print("ğŸš€ Stage 1: Starting OCR with PARALLEL processing...")
    
    send_progress = get_progress_function()
    
    try:
        # ä¸¦åˆ—OCRã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        from app.services.ocr.parallel import extract_text_with_parallel
        
        result = await extract_text_with_parallel(image_path, session_id)
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
        legacy_result = {
            "stage": 1,
            "success": result.success,
            "extracted_text": result.extracted_text,
            "ocr_engine": result.metadata.get("selected_engine", "gemini-2.0-flash"),
            "mode": "parallel_ocr_with_fallback"
        }
        
        if result.success:
            # æˆåŠŸæ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            processing_mode = result.metadata.get("processing_mode", "unknown")
            
            legacy_result.update({
                "text_length": len(result.extracted_text),
                "ocr_service": result.metadata.get("provider", "Parallel OCR Service"),
                "processing_mode": processing_mode,
                "parallel_enabled": result.metadata.get("parallel_enabled", False),
                "selected_engine": result.metadata.get("selected_engine", "unknown"),
                "engines_used": result.metadata.get("engines_used", []),
                "all_results": result.metadata.get("all_results", {}),
                "selection_reason": result.metadata.get("selection_reason", ""),
                "processing_time": result.metadata.get("processing_time"),
                "features": result.metadata.get("features", ["menu_optimized", "japanese_text", "high_precision"])
            })
            
            # æ€§èƒ½å‘ä¸Šã®è¡¨ç¤º
            if result.metadata.get("parallel_enabled", False):
                print(f"ğŸš€ PARALLEL OCR successful - {len(result.extracted_text)} characters extracted with enhanced accuracy")
            else:
                processing_mode_display = processing_mode.replace("_", " ").title()
                print(f"ğŸ”„ {processing_mode_display} used - {len(result.extracted_text)} characters extracted")
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥ã¯ process_menu_background ã§çµ±ä¸€ç®¡ç†
            # if session_id:
            #     await send_progress(session_id, 1, "completed", "ğŸš€ ä¸¦åˆ—OCRå®Œäº†", {
            #         "extracted_text": result.extracted_text,
            #         "text_preview": result.extracted_text[:100] + "..." if len(result.extracted_text) > 100 else result.extracted_text,
            #         "ocr_service": result.metadata.get("provider", "Parallel OCR Service"),
            #         "processing_mode": processing_mode,
            #         "parallel_enabled": result.metadata.get("parallel_enabled", False)
            #     })
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
            legacy_result.update({
                "error": result.error,
                "detailed_error": result.metadata
            })
            
            print(f"âŒ Parallel OCR failed: {result.error}")
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥
            if session_id and send_progress:
                await send_progress(session_id, 1, "error", f"ğŸš€ ä¸¦åˆ—OCRã‚¨ãƒ©ãƒ¼: {result.error}", result.metadata)
        
        return legacy_result
        
    except Exception as e:
        print(f"âŒ Stage 1 Parallel OCR Service Failed: {e}")
        
        error_result = {
            "stage": 1,
            "success": False,
            "error": f"ä¸¦åˆ—OCRã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "ocr_engine": "parallel_multi_engine",
            "mode": "parallel_ocr_with_fallback",
            "detailed_error": {
                "error_type": "parallel_ocr_service_error",
                "original_error": str(e),
                "suggestions": [
                    "GEMINI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "ä¸¦åˆ—OCRã®è¨­å®šï¼ˆENABLE_PARALLEL_OCRï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "Google Vision APIã¾ãŸã¯Gemini APIã®åˆ©ç”¨çŠ¶æ³ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ]
            },
            "extracted_text": ""
        }
        
        if session_id and send_progress:
            await send_progress(session_id, 1, "error", f"ğŸš€ ä¸¦åˆ—OCRã‚¨ãƒ©ãƒ¼: {str(e)}", error_result["detailed_error"])
        
        return error_result

# Stage 2: æ—¥æœ¬èªã®ã¾ã¾ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ»æ çµ„ã¿ä½œæˆ (ä¸¦åˆ—åŒ–å¯¾å¿œç‰ˆ)
async def stage2_categorize_openai_exclusive(extracted_text: str, session_id: str = None) -> dict:
    """Stage 2: OpenAI Function Callingã‚’ä½¿ã£ã¦æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã®ã¾ã¾ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆä¸¦åˆ—åŒ–å¯¾å¿œï¼‰"""
    print("ğŸ·ï¸ Stage 2: Starting Japanese categorization with PARALLEL PROCESSING...")
    
    send_progress = get_progress_function()
    
    try:
        # ä¸¦åˆ—ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        from app.services.category.parallel import categorize_menu_with_parallel
        
        result = await categorize_menu_with_parallel(extracted_text, session_id)
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
        legacy_result = {
            "stage": 2,
            "success": result.success,
            "categories": result.categories,
            "uncategorized": result.uncategorized,
            "categorization_engine": "openai-function-calling-parallel",
            "mode": "parallel_categorization"
        }
        
        if result.success:
            # æˆåŠŸæ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            total_items = sum(len(items) for items in result.categories.values())
            legacy_result.update({
                "total_items": total_items,
                "total_categories": len(result.categories),
                "uncategorized_count": len(result.uncategorized),
                "categorization_service": "Parallel Categorization Service",
                "parallel_processing": True,
                "processing_time": result.metadata.get('processing_time', 0),
                "parallel_strategy": result.metadata.get('parallel_strategy', 'unknown')
            })
            
            print(f"âœ… Stage 2 PARALLEL Categorization Complete: {total_items} items in {len(result.categories)} categories")
            
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
            legacy_result.update({
                "error": result.error,
                "detailed_error": result.metadata
            })
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥
            if session_id and send_progress:
                await send_progress(session_id, 2, "error", f"ğŸ·ï¸ ä¸¦åˆ—ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ©ãƒ¼: {result.error}", result.metadata)
        
        return legacy_result
        
    except Exception as e:
        print(f"âŒ Stage 2 Parallel Categorization Failed: {e}")
        
        error_result = {
            "stage": 2,
            "success": False,
            "error": f"ä¸¦åˆ—ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "categorization_engine": "openai-function-calling-parallel",
            "mode": "parallel_categorization",
            "detailed_error": {
                "error_type": "parallel_categorization_error",
                "original_error": str(e),
                "suggestions": [
                    "Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„", 
                    "ä¸¦åˆ—å‡¦ç†è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆENABLE_PARALLEL_CATEGORIZATIONï¼‰"
                ]
            },
            "categories": {}
        }
        
        if session_id and send_progress:
            await send_progress(session_id, 2, "error", f"ğŸ·ï¸ ä¸¦åˆ—ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}", error_result["detailed_error"])
        
        return error_result

# Stage 2: æ—¥æœ¬èªã®ã¾ã¾ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ãƒ»æ çµ„ã¿ä½œæˆ (å¾“æ¥ç‰ˆãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨)
async def stage2_categorize_openai_exclusive_legacy(extracted_text: str, session_id: str = None) -> dict:
    """Stage 2: OpenAI Function Callingã‚’ä½¿ã£ã¦æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã®ã¾ã¾ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆå¾“æ¥ç‰ˆï¼‰"""
    print("ğŸ·ï¸ Stage 2: Starting Japanese categorization with OpenAI Function Calling (Legacy Mode)...")
    
    send_progress = get_progress_function()
    
    try:
        # å¾“æ¥ã®ã‚«ãƒ†ã‚´ãƒªã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        from app.services.category import category_categorize_menu
        
        result = await category_categorize_menu(extracted_text, session_id)
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
        legacy_result = {
            "stage": 2,
            "success": result.success,
            "categories": result.categories,
            "uncategorized": result.uncategorized,
            "categorization_engine": "openai-function-calling",
            "mode": "openai_exclusive_legacy"
        }
        
        if result.success:
            # æˆåŠŸæ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            total_items = sum(len(items) for items in result.categories.values())
            legacy_result.update({
                "total_items": total_items,
                "total_categories": len(result.categories),
                "uncategorized_count": len(result.uncategorized),
                "categorization_service": "OpenAI Function Calling (Legacy)"
            })
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
            legacy_result.update({
                "error": result.error,
                "detailed_error": result.metadata
            })
            
            if session_id and send_progress:
                await send_progress(session_id, 2, "error", f"ğŸ·ï¸ OpenAI ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ©ãƒ¼: {result.error}", result.metadata)
        
        return legacy_result
        
    except Exception as e:
        print(f"âŒ Stage 2 OpenAI Categorization Failed: {e}")
        
        error_result = {
            "stage": 2,
            "success": False,
            "error": f"OpenAI ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "categorization_engine": "openai-function-calling",
            "mode": "openai_exclusive_legacy",
            "detailed_error": {
                "error_type": "openai_categorization_error",
                "original_error": str(e),
                "suggestions": [
                    "OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "OpenAI APIã®åˆ©ç”¨çŠ¶æ³ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "openaiãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                ]
            },
            "categories": {}
        }
        
        if session_id and send_progress:
            await send_progress(session_id, 2, "error", f"ğŸ·ï¸ OpenAI ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚¨ãƒ©ãƒ¼: {str(e)}", error_result["detailed_error"])
        
        return error_result

# Stage 3: ç¿»è¨³ (ä¸¦åˆ—ç¿»è¨³ç‰ˆ)
async def stage3_translate_with_fallback(categorized_data: dict, session_id: str = None) -> dict:
    """Stage 3: ä¸¦åˆ—ç¿»è¨³ã§é«˜é€ŸåŒ–ï¼ˆGoogle Translate + OpenAI ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    print("ğŸš€ Stage 3: Starting PARALLEL translation with enhanced performance...")
    
    send_progress = get_progress_function()
    
    try:
        # ä¸¦åˆ—ç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        from app.services.translation.parallel import translate_menu_with_parallel
        
        result = await translate_menu_with_parallel(categorized_data, session_id)
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
        legacy_result = {
            "stage": 3,
            "success": result.success,
            "translated_categories": result.translated_categories,
            "translation_method": result.translation_method,
            "translation_architecture": "parallel_translation_with_fallback"
        }
        
        if result.success:
            # æˆåŠŸæ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            total_items = sum(len(items) for items in result.translated_categories.values())
            processing_mode = result.metadata.get("processing_mode", "unknown")
            
            legacy_result.update({
                "total_items": total_items,
                "total_categories": len(result.translated_categories),
                "translation_service": result.metadata.get("provider", "Parallel Translation Service"),
                "processing_mode": processing_mode,
                "parallel_enabled": processing_mode == "parallel_direct",
                "fallback_used": result.metadata.get("fallback_used", False),
                "failed_categories": result.metadata.get("failed_categories"),
                "processing_time": result.metadata.get("total_processing_time")
            })
            
            # æ€§èƒ½å‘ä¸Šã®è¡¨ç¤º
            if processing_mode == "parallel_direct":
                print(f"ğŸš€ PARALLEL Translation successful - {total_items} items processed with enhanced speed")
            else:
                print(f"ğŸ”„ Sequential fallback used - {total_items} items processed")
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥ã¯ process_menu_background ã§çµ±ä¸€ç®¡ç†
            # if session_id:
            #     await send_progress(session_id, 3, "completed", "ğŸš€ ä¸¦åˆ—ç¿»è¨³å®Œäº†", {
            #         "translatedCategories": result.translated_categories,
            #         "translation_method": result.translation_method,
            #         "total_items": total_items,
            #         "processing_mode": processing_mode,
            #         "parallel_enabled": processing_mode == "parallel_direct"
            #     })
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
            legacy_result.update({
                "error": result.error,
                "detailed_error": result.metadata
            })
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥
            if session_id and send_progress:
                await send_progress(session_id, 3, "error", f"ğŸš€ ä¸¦åˆ—ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {result.error}", result.metadata)
        
        return legacy_result
        
    except Exception as e:
        print(f"âŒ Stage 3 Parallel Translation Service Failed: {e}")
        
        error_result = {
            "stage": 3,
            "success": False,
            "error": f"ä¸¦åˆ—ç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "translation_architecture": "parallel_translation_with_fallback",
            "detailed_error": {
                "error_type": "parallel_translation_service_error",
                "original_error": str(e),
                "suggestions": [
                    "GOOGLE_CREDENTIALS_JSONã¾ãŸã¯OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "ä¸¦åˆ—ç¿»è¨³ã®è¨­å®šï¼ˆENABLE_PARALLEL_TRANSLATIONï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "Google Translate APIã¾ãŸã¯OpenAI APIã®åˆ©ç”¨çŠ¶æ³ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ]
            },
            "translated_categories": {}
        }
        
        if session_id and send_progress:
            await send_progress(session_id, 3, "error", f"ğŸš€ ä¸¦åˆ—ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}", error_result["detailed_error"])
        
        return error_result

# Stage 4: è©³ç´°èª¬æ˜è¿½åŠ  (ä¸¦åˆ—å‡¦ç†ç‰ˆ)
async def stage4_add_descriptions(translated_data: dict, session_id: str = None) -> dict:
    """Stage 4: ä¸¦åˆ—è©³ç´°èª¬æ˜ã§é«˜é€ŸåŒ–ï¼ˆOpenAIä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ + ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
    print("ğŸš€ Stage 4: Adding detailed descriptions with PARALLEL processing...")
    
    send_progress = get_progress_function()
    
    try:
        # ä¸¦åˆ—è©³ç´°èª¬æ˜ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨
        from app.services.description.parallel import add_descriptions_with_parallel
        
        result = await add_descriptions_with_parallel(translated_data, session_id)
        
        # ãƒ¬ã‚¬ã‚·ãƒ¼å½¢å¼ã«å¤‰æ›
        legacy_result = {
            "stage": 4,
            "success": result.success,
            "final_menu": result.final_menu,
            "description_method": result.description_method,
            "description_architecture": "parallel_description_with_fallback"
        }
        
        if result.success:
            # æˆåŠŸæ™‚ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            total_items = sum(len(items) for items in result.final_menu.values())
            processing_mode = result.metadata.get("processing_mode", "unknown")
            
            legacy_result.update({
                "total_items": total_items,
                "categories_processed": len(result.final_menu),
                "description_service": result.metadata.get("provider", "OpenAI API (Parallel)"),
                "processing_mode": processing_mode,
                "parallel_enabled": result.metadata.get("parallel_enabled", False),
                "fallback_used": result.metadata.get("fallback_reason") is not None,
                "failed_categories": result.metadata.get("failed_categories"),
                "processing_time": result.metadata.get("processing_time"),
                "features": result.metadata.get("features", [])
            })
            
            # æ€§èƒ½å‘ä¸Šã®è¡¨ç¤º
            if result.metadata.get("parallel_enabled", False):
                print(f"ğŸš€ PARALLEL Description successful - {total_items} items processed with enhanced speed")
            else:
                processing_mode_display = processing_mode.replace("_", " ").title()
                print(f"ğŸ”„ {processing_mode_display} used - {total_items} items processed")
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥ã¯ process_menu_background ã§çµ±ä¸€ç®¡ç†
            # if session_id:
            #     await send_progress(session_id, 4, "completed", "ğŸš€ ä¸¦åˆ—è©³ç´°èª¬æ˜å®Œäº†", {
            #         "finalMenu": result.final_menu,
            #         "description_method": result.description_method,
            #         "total_items": total_items,
            #         "processing_mode": processing_mode,
            #         "parallel_enabled": result.metadata.get("parallel_enabled", False)
            #     })
            
        else:
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®è©³ç´°æƒ…å ±ã‚’è¿½åŠ 
            legacy_result.update({
                "error": result.error,
                "detailed_error": result.metadata
            })
            
            print(f"âŒ Parallel Description Generation failed: {result.error}")
            
            # é€²è¡ŒçŠ¶æ³é€šçŸ¥
            if session_id and send_progress:
                await send_progress(session_id, 4, "error", f"ğŸš€ ä¸¦åˆ—è©³ç´°èª¬æ˜ã‚¨ãƒ©ãƒ¼: {result.error}", result.metadata)
        
        return legacy_result
        
    except Exception as e:
        print(f"âŒ Stage 4 Parallel Description Service Failed: {e}")
        
        error_result = {
            "stage": 4,
            "success": False,
            "error": f"ä¸¦åˆ—è©³ç´°èª¬æ˜ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            "description_architecture": "parallel_description_with_fallback",
            "detailed_error": {
                "error_type": "parallel_description_service_error",
                "original_error": str(e),
                "suggestions": [
                    "OPENAI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                    "ä¸¦åˆ—è©³ç´°èª¬æ˜ã®è¨­å®šï¼ˆENABLE_PARALLEL_DESCRIPTIONï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    "OpenAI APIã®åˆ©ç”¨çŠ¶æ³ãƒ»ã‚¯ã‚©ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
                ]
            },
            "final_menu": {}
        }
        
        if session_id and send_progress:
            await send_progress(session_id, 4, "error", f"ğŸš€ ä¸¦åˆ—è©³ç´°èª¬æ˜ã‚¨ãƒ©ãƒ¼: {str(e)}", error_result["detailed_error"])
        
        return error_result

# Stage 5: ç”»åƒç”Ÿæˆ (Celery + Redis éåŒæœŸå‡¦ç†ç‰ˆ)
async def stage5_generate_images(final_menu: dict, session_id: str = None) -> dict:
    """Stage 5: Celery + RediséåŒæœŸå‡¦ç†ã§Imagen 3ç”»åƒã‚’ç”Ÿæˆ"""
    print("ğŸ¨ Stage 5: Starting async image generation with Celery + Redis...")
    
    try:
        from app.services.image.async_manager import get_async_manager
        
        # AsyncImageManagerã‚’å–å¾—
        async_manager = get_async_manager()
        
        # éåŒæœŸç”»åƒç”Ÿæˆã‚’é–‹å§‹
        success, message, job_id = async_manager.start_async_generation(final_menu, session_id)
        
        if not success or not job_id:
            # éåŒæœŸå‡¦ç†é–‹å§‹ã«å¤±æ•—ã—ãŸå ´åˆã¯å¾“æ¥ã®åŒæœŸå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            print(f"âš ï¸ Async generation failed ({message}), falling back to sync processing...")
            result = await image_generate_images(final_menu, session_id)
            
            return {
                "stage": 5,
                "success": result.success,
                "images_generated": result.images_generated,
                "total_images": result.total_images,
                "total_items": result.total_items,
                "image_method": result.image_method + "_sync_fallback",
                "image_architecture": "imagen3_food_photography_sync",
                "fallback_reason": message
            }
        
        print(f"ğŸš€ Async image generation started: job_id={job_id}")
        
        # ã‚¸ãƒ§ãƒ–å®Œäº†ã¾ã§ç›£è¦–
        return await monitor_async_image_job(job_id, session_id, final_menu)
        
    except Exception as e:
        print(f"âŒ Stage 5 Async Image Generation Failed: {e}")
        
        # ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆã‚‚åŒæœŸå‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        try:
            print("âš ï¸ Exception occurred, attempting sync fallback...")
            result = await image_generate_images(final_menu, session_id)
            
            return {
                "stage": 5,
                "success": result.success,
                "images_generated": result.images_generated,
                "total_images": result.total_images,
                "total_items": result.total_items,
                "image_method": result.image_method + "_exception_fallback",
                "image_architecture": "imagen3_food_photography_sync",
                "fallback_reason": f"Exception in async processing: {str(e)}"
            }
        except Exception as sync_error:
            # åŒæœŸå‡¦ç†ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹
            error_result = {
                "stage": 5,
                "success": False,
                "error": f"ç”»åƒç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
                "image_architecture": "imagen3_async_with_sync_fallback",
                "detailed_error": {
                    "error_type": "both_async_and_sync_failed",
                    "async_error": str(e),
                    "sync_error": str(sync_error),
                    "suggestions": [
                        "Redisã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "Celeryãƒ¯ãƒ¼ã‚«ãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "GEMINI_API_KEYãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„",
                        "IMAGE_GENERATION_ENABLEDãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„"
                    ]
                },
                "images_generated": {}
            }
            
            return error_result

async def monitor_async_image_job(job_id: str, session_id: str = None, final_menu: dict = None) -> dict:
    """éåŒæœŸç”»åƒç”Ÿæˆã‚¸ãƒ§ãƒ–ã‚’ç›£è¦–ã—ã€å®Œäº†ã¾ã§å¾…æ©Ÿ"""
    from app.services.image.async_manager import get_async_manager
    
    send_progress = get_progress_function()
    async_manager = get_async_manager()
    start_time = asyncio.get_event_loop().time()
    last_progress = -1
    monitoring_interval = 2.0  # 2ç§’é–“éš”ã§ãƒã‚§ãƒƒã‚¯
    max_wait_time = 300  # æœ€å¤§5åˆ†å¾…æ©Ÿ
    
    print(f"ğŸ“Š Starting job monitoring: job_id={job_id}")
    
    try:
        while asyncio.get_event_loop().time() - start_time < max_wait_time:
            # ã‚¸ãƒ§ãƒ–ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—
            status_info = async_manager.get_job_status(job_id)
            
            if not status_info.get("found", False):
                print(f"âŒ Job not found: {job_id}")
                break
            
            current_status = status_info.get("status", "unknown")
            current_progress = status_info.get("progress_percent", 0)
            
            # é€²è¡ŒçŠ¶æ³ãŒå¤‰åŒ–ã—ãŸå ´åˆã®ã¿é€šçŸ¥
            if current_progress != last_progress:
                elapsed = int(asyncio.get_event_loop().time() - start_time)
                
                # é€²è¡ŒçŠ¶æ³ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€šçŸ¥
                if session_id and send_progress:
                    processing_info = status_info.get("processing_info", {})
                    await send_progress(
                        session_id, 5, "active",
                        f"ğŸ¨ éåŒæœŸç”»åƒç”Ÿæˆä¸­: {current_progress}% (çµŒéæ™‚é–“: {elapsed}ç§’)",
                        {
                            "job_id": job_id,
                            "progress_percent": current_progress,
                            "status": current_status,
                            "async_processing": True,
                            "processing_info": {
                                "completed_chunks": status_info.get("completed_chunks", 0),
                                "total_chunks": status_info.get("total_chunks", 0),
                                "total_items": status_info.get("total_items", 0),
                                "elapsed_time": elapsed
                            }
                        }
                    )
                
                print(f"ğŸ“Š [{elapsed}s] Job {job_id}: {current_status} - {current_progress}%")
                last_progress = current_progress
            
            # å®Œäº†ãƒã‚§ãƒƒã‚¯
            if current_status in ["completed", "partial_completed", "failed"]:
                print(f"âœ… Job completed: {job_id} - Status: {current_status}")
                
                # çµæœã‚’æ§‹ç¯‰
                if current_status in ["completed", "partial_completed"]:
                    images_generated = status_info.get("images_generated", {})
                    total_images = status_info.get("total_images", 0)
                    total_items = sum(len(items) for items in final_menu.values()) if final_menu else status_info.get("total_items", 0)
                    
                    # æˆåŠŸç‡è¨ˆç®—
                    success_rate = (total_images / total_items * 100) if total_items > 0 else 0
                    
                    return {
                        "stage": 5,
                        "success": True,
                        "images_generated": images_generated,
                        "total_images": total_images,
                        "total_items": total_items,
                        "image_method": "celery_async_imagen3",
                        "image_architecture": "imagen3_async_food_photography",
                        "job_id": job_id,
                        "processing_time": int(asyncio.get_event_loop().time() - start_time),
                        "success_rate": round(success_rate, 2),
                        "async_processing_completed": True
                    }
                else:
                    # å¤±æ•—
                    return {
                        "stage": 5,
                        "success": False,
                        "error": f"Async image generation failed: {current_status}",
                        "job_id": job_id,
                        "image_architecture": "imagen3_async_food_photography",
                        "processing_time": int(asyncio.get_event_loop().time() - start_time),
                        "images_generated": {}
                    }
            
            # æ¬¡ã®ãƒã‚§ãƒƒã‚¯ã¾ã§å¾…æ©Ÿ
            await asyncio.sleep(monitoring_interval)
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        print(f"â° Job monitoring timeout: {job_id}")
        return {
            "stage": 5,
            "success": False,
            "error": f"Image generation timeout after {max_wait_time} seconds",
            "job_id": job_id,
            "image_architecture": "imagen3_async_food_photography",
            "timeout": True,
            "images_generated": {}
        }
        
    except Exception as e:
        print(f"âŒ Job monitoring error: {e}")
        return {
            "stage": 5,
            "success": False,
            "error": f"Job monitoring failed: {str(e)}",
            "job_id": job_id,
            "image_architecture": "imagen3_async_food_photography",
            "monitoring_error": True,
            "images_generated": {}
        } 